post_id,subreddit,author,title,content,score,num_comments,upvote_ratio,created_utc,permalink,raw_data
1qd696s,MachineLearning,44th--Hokage,"Nvidia: End-to-End Test-Time Training for Long Context aka Being Able To Update A Model's Weights In Real-Time As You Use It | ""TTT changes the paradigm from retrieving info to learning it on the fly...the TTT model treats the context window as a dataset &amp; trains itself on it in real-time."" [R]","####TL;DR:
The paper describes a mechanism that essentially turns the context window into a training dataset for a ""fast weight"" update loop:

 * **Inner Loop:** The model runs a mini-gradient descent on the context during inference. It updates specific MLP layers to ""learn"" the current context.
 * **Outer Loop:** The model's initial weights are meta-learned during training to be ""highly updateable"" or optimized for this test-time adaptation

**From the Paper:** ""Overall, our empirical observations strongly indicate that TTT-E2E should produce the same trend as full attention for scaling with training compute in large-budget production runs.""




---



####Abstract:

&gt;We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture a Transformer with sliding-window attention. 
&gt;
&gt;**However, our model continues learning at test time via next-token prediction on the given context, compressing the context it reads into its weights.** In addition, we improve the model's initialization for learning at test time via meta-learning at training time. Overall, our method, a form of Test-Time Training (TTT), is End-to-End (E2E) both at test time (via next-token prediction) and training time (via meta-learning), in contrast to previous forms. We conduct extensive experiments with a focus on scaling properties. 
&gt;
&gt;In particular, for 3B models trained with 164B tokens, our method (TTT-E2E) scales with context length in the same way as Transformer with full attention, while others, such as Mamba 2 and Gated DeltaNet, do not. However, similar to RNNs, TTT-E2E has constant inference latency regardless of context length, making it 2.7x faster than full attention for 128K context. **Our code is publicly available.**


---

####Layman's Explanation:

Think of this paper as solving the memory bottleneck by fundamentally changing how a model processes information. Imagine you are taking a massive open-book exam. 

A standard Transformer (like GPT-4) is the student who frantically re-reads every single page of the textbook before answering every single question. This strategy guarantees they find the specific details (perfect recall), but as the textbook gets thicker, they get exponentially slower until they simply cannot finish the test in time. 

On the other hand, alternatives like RNNs or Mamba try to summarize the entire textbook onto a single index card. They can answer questions instantly because they don't have to look back at the book, but for long, complex subjects, they eventually run out of space on the card and start forgetting crucial information.

This new method, Test-Time Training (TTT), changes the paradigm from retrieving information to learning it on the fly. Instead of re-reading the book or summarizing it onto a card, the TTT model treats the context window as a dataset and actually trains itself on it in real-time. It performs a mini-gradient descent update on its own neural weights as it reads. **This is equivalent to a student who reads the textbook and physically rewires their brain to master the subject matter before the test.** 

Because the information is now compressed into the model's actual intelligence (its weights) rather than a temporary cache, the model can answer questions instantly (matching the constant speed of the fast index-card models) but with the high accuracy and scaling capability of the slow, page-turning Transformers. 

**This effectively decouples intelligence from memory costs, allowing for massive context lengths without the usual slowdown.**

---


######Link to the Paper: https://arxiv.org/pdf/2512.23675

---


######Link to the Open-Sourced Official Implementation of End-to-End Test Time Training for Long Context: https://github.com/test-time-training/e2e",250,20,0.97,1768441406.0,/r/MachineLearning/comments/1qd696s/nvidia_endtoend_testtime_training_for_long/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""####TL;DR:\nThe paper describes a mechanism that essentially turns the context window into a training dataset for a \""fast weight\"" update loop:\n\n * **Inner Loop:** The model runs a mini-gradient descent on the context during inference. It updates specific MLP layers to \""learn\"" the current context.\n * **Outer Loop:** The model's initial weights are meta-learned during training to be \""highly updateable\"" or optimized for this test-time adaptation\n\n**From the Paper:** \""Overall, our empirical observations strongly indicate that TTT-E2E should produce the same trend as full attention for scaling with training compute in large-budget production runs.\""\n\n\n\n\n---\n\n\n\n####Abstract:\n\n&gt;We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture a Transformer with sliding-window attention. \n&gt;\n&gt;**However, our model continues learning at test time via next-token prediction on the given context, compressing the context it reads into its weights.** In addition, we improve the model's initialization for learning at test time via meta-learning at training time. Overall, our method, a form of Test-Time Training (TTT), is End-to-End (E2E) both at test time (via next-token prediction) and training time (via meta-learning), in contrast to previous forms. We conduct extensive experiments with a focus on scaling properties. \n&gt;\n&gt;In particular, for 3B models trained with 164B tokens, our method (TTT-E2E) scales with context length in the same way as Transformer with full attention, while others, such as Mamba 2 and Gated DeltaNet, do not. However, similar to RNNs, TTT-E2E has constant inference latency regardless of context length, making it 2.7x faster than full attention for 128K context. **Our code is publicly available.**\n\n\n---\n\n####Layman's Explanation:\n\nThink of this paper as solving the memory bottleneck by fundamentally changing how a model processes information. Imagine you are taking a massive open-book exam. \n\nA standard Transformer (like GPT-4) is the student who frantically re-reads every single page of the textbook before answering every single question. This strategy guarantees they find the specific details (perfect recall), but as the textbook gets thicker, they get exponentially slower until they simply cannot finish the test in time. \n\nOn the other hand, alternatives like RNNs or Mamba try to summarize the entire textbook onto a single index card. They can answer questions instantly because they don't have to look back at the book, but for long, complex subjects, they eventually run out of space on the card and start forgetting crucial information.\n\nThis new method, Test-Time Training (TTT), changes the paradigm from retrieving information to learning it on the fly. Instead of re-reading the book or summarizing it onto a card, the TTT model treats the context window as a dataset and actually trains itself on it in real-time. It performs a mini-gradient descent update on its own neural weights as it reads. **This is equivalent to a student who reads the textbook and physically rewires their brain to master the subject matter before the test.** \n\nBecause the information is now compressed into the model's actual intelligence (its weights) rather than a temporary cache, the model can answer questions instantly (matching the constant speed of the fast index-card models) but with the high accuracy and scaling capability of the slow, page-turning Transformers. \n\n**This effectively decouples intelligence from memory costs, allowing for massive context lengths without the usual slowdown.**\n\n---\n\n\n######Link to the Paper: https://arxiv.org/pdf/2512.23675\n\n---\n\n\n######Link to the Open-Sourced Official Implementation of End-to-End Test Time Training for Long Context: https://github.com/test-time-training/e2e"", ""author_fullname"": ""t2_1huav90ix8"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""is_gallery"": true, ""title"": ""Nvidia: End-to-End Test-Time Training for Long Context aka Being Able To Update A Model's Weights In Real-Time As You Use It | \""TTT changes the paradigm from retrieving info to learning it on the fly...the TTT model treats the context window as a dataset &amp; trains itself on it in real-time.\"" [R]"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": ""three"", ""downs"": 0, ""thumbnail_height"": 83, ""top_awarded_type"": null, ""hide_score"": false, ""media_metadata"": {""kmbdv3w84fdg1"": {""status"": ""valid"", ""e"": ""Image"", ""m"": ""image/jpg"", ""p"": [{""y"": 87, ""x"": 108, ""u"": ""https://preview.redd.it/kmbdv3w84fdg1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=83091382da1ce9506372f2f454d2c72c29321e5a""}, {""y"": 175, ""x"": 216, ""u"": ""https://preview.redd.it/kmbdv3w84fdg1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4feef6e940354ab35d3d8ac83566b6d1b85c4284""}, {""y"": 260, ""x"": 320, ""u"": ""https://preview.redd.it/kmbdv3w84fdg1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=85fe9694dc001108bef6d5261f0cf0f3669d0175""}, {""y"": 521, ""x"": 640, ""u"": ""https://preview.redd.it/kmbdv3w84fdg1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f4c4f8bca8bdd46a43593ed14523e733a08316ef""}, {""y"": 781, ""x"": 960, ""u"": ""https://preview.redd.it/kmbdv3w84fdg1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3027c022ce731aca69e05b7878b67459a56de925""}], ""s"": {""y"": 819, ""x"": 1006, ""u"": ""https://preview.redd.it/kmbdv3w84fdg1.jpg?width=1006&amp;format=pjpg&amp;auto=webp&amp;s=3a4be5431d1e612ca387ab8e0d15ae2d7ddec873""}, ""id"": ""kmbdv3w84fdg1""}, ""7htdqvw84fdg1"": {""status"": ""valid"", ""e"": ""Image"", ""m"": ""image/jpg"", ""p"": [{""y"": 54, ""x"": 108, ""u"": ""https://preview.redd.it/7htdqvw84fdg1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0a0e79498a7c43125f715588cac4cbd1102fff2""}, {""y"": 109, ""x"": 216, ""u"": ""https://preview.redd.it/7htdqvw84fdg1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c30454eaf0c257ed8f483f838af7ce9244d06637""}, {""y"": 161, ""x"": 320, ""u"": ""https://preview.redd.it/7htdqvw84fdg1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=737d2f394d89604b857532636edad1fb0460a7d0""}, {""y"": 323, ""x"": 640, ""u"": ""https://preview.redd.it/7htdqvw84fdg1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=08420927ebcb5b705cc15ccb63087c2b6035f620""}, {""y"": 485, ""x"": 960, ""u"": ""https://preview.redd.it/7htdqvw84fdg1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3deec7068485f6cf1b6e585a0fcc9f7311bddfd2""}], ""s"": {""y"": 511, ""x"": 1011, ""u"": ""https://preview.redd.it/7htdqvw84fdg1.jpg?width=1011&amp;format=pjpg&amp;auto=webp&amp;s=f77505dbfd35ecf4d377458644ca14d30aaeb45d""}, ""id"": ""7htdqvw84fdg1""}, ""if46fiq84fdg1"": {""status"": ""valid"", ""e"": ""Image"", ""m"": ""image/jpg"", ""p"": [{""y"": 64, ""x"": 108, ""u"": ""https://preview.redd.it/if46fiq84fdg1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=37eadbe93f40b2c43da4a59872bfa5f5da14e817""}, {""y"": 128, ""x"": 216, ""u"": ""https://preview.redd.it/if46fiq84fdg1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2160dd040351a213bdb9c5a96c9c39c6da5ba5bf""}, {""y"": 190, ""x"": 320, ""u"": ""https://preview.redd.it/if46fiq84fdg1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b3f6a6b6b0d018e702f3fcfcbd380c9d6a732829""}, {""y"": 380, ""x"": 640, ""u"": ""https://preview.redd.it/if46fiq84fdg1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a8811a358af2a3ab6db3c23b5b7486a17797844c""}, {""y"": 570, ""x"": 960, ""u"": ""https://preview.redd.it/if46fiq84fdg1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b34ac77231f82759633e84a6dcf376906f86faac""}], ""s"": {""y"": 595, ""x"": 1002, ""u"": ""https://preview.redd.it/if46fiq84fdg1.jpg?width=1002&amp;format=pjpg&amp;auto=webp&amp;s=c4328af6f380e808010d4c417a1e6717f8d2336f""}, ""id"": ""if46fiq84fdg1""}, ""xkqhaev84fdg1"": {""status"": ""valid"", ""e"": ""Image"", ""m"": ""image/jpg"", ""p"": [{""y"": 16, ""x"": 108, ""u"": ""https://preview.redd.it/xkqhaev84fdg1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f13c6ce5c55b70d995e30ac406374ab424a0a87e""}, {""y"": 32, ""x"": 216, ""u"": ""https://preview.redd.it/xkqhaev84fdg1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ef8c0ec8afb7b17a2b21a239c955449963c26fe8""}, {""y"": 47, ""x"": 320, ""u"": ""https://preview.redd.it/xkqhaev84fdg1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8a697f53300d6a7d6c2dce04308d944bfea7b6f0""}, {""y"": 95, ""x"": 640, ""u"": ""https://preview.redd.it/xkqhaev84fdg1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=07af9349544ab548e70f3d65639e286b0af8cc63""}, {""y"": 143, ""x"": 960, ""u"": ""https://preview.redd.it/xkqhaev84fdg1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=904ca3bdad62ee08a0aa01cb42eccfa269ece90f""}, {""y"": 161, ""x"": 1080, ""u"": ""https://preview.redd.it/xkqhaev84fdg1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=56cf9c66b60414bc053400c3622a4c76774ac4d3""}], ""s"": {""y"": 161, ""x"": 1080, ""u"": ""https://preview.redd.it/xkqhaev84fdg1.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=aeb308f3dc941e5f007a5873ffcac8e073e7262d""}, ""id"": ""xkqhaev84fdg1""}, ""hcdrmut84fdg1"": {""status"": ""valid"", ""e"": ""Image"", ""m"": ""image/jpg"", ""p"": [{""y"": 41, ""x"": 108, ""u"": ""https://preview.redd.it/hcdrmut84fdg1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d49a96a0b0a6779e04bf93c4c56cf3621fe6e74""}, {""y"": 82, ""x"": 216, ""u"": ""https://preview.redd.it/hcdrmut84fdg1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9970d30743278bcef47ab0feb85cc1cd26408c21""}, {""y"": 122, ""x"": 320, ""u"": ""https://preview.redd.it/hcdrmut84fdg1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ed7f3071ac5472817f2095a9f13e99b9693b8d1""}, {""y"": 244, ""x"": 640, ""u"": ""https://preview.redd.it/hcdrmut84fdg1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf4ded7a0d4acdf730e51f7e6f5096d1226085f9""}, {""y"": 366, ""x"": 960, ""u"": ""https://preview.redd.it/hcdrmut84fdg1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9c21fb5d845974c5ee3ffaf3844e7a47e8c5285b""}], ""s"": {""y"": 381, ""x"": 999, ""u"": ""https://preview.redd.it/hcdrmut84fdg1.jpg?width=999&amp;format=pjpg&amp;auto=webp&amp;s=510d82af2e04e7847db5e4fe6e596dac1448ca9c""}, ""id"": ""hcdrmut84fdg1""}, ""03jvuys84fdg1"": {""status"": ""valid"", ""e"": ""Image"", ""m"": ""image/jpg"", ""p"": [{""y"": 16, ""x"": 108, ""u"": ""https://preview.redd.it/03jvuys84fdg1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2cd2001b14275857ca85085446158547af23a507""}, {""y"": 32, ""x"": 216, ""u"": ""https://preview.redd.it/03jvuys84fdg1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=11a3281fdc9accb9f6ddac7b58145da6f660163b""}, {""y"": 47, ""x"": 320, ""u"": ""https://preview.redd.it/03jvuys84fdg1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4d6361e1b4a6e6c1c9a6092166c7551022f8896e""}, {""y"": 95, ""x"": 640, ""u"": ""https://preview.redd.it/03jvuys84fdg1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=eeeed52a2ada87390b2c204fc17bbb468b89eab6""}, {""y"": 143, ""x"": 960, ""u"": ""https://preview.redd.it/03jvuys84fdg1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d2c9f649fbece89c080711cc03725c44d53aa7d3""}, {""y"": 161, ""x"": 1080, ""u"": ""https://preview.redd.it/03jvuys84fdg1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=59af0e0c4ab7084a85f93ed7a00d2b26b058c434""}], ""s"": {""y"": 161, ""x"": 1080, ""u"": ""https://preview.redd.it/03jvuys84fdg1.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=9682fde5a3f80dedd3272a98941ecf340f198f51""}, ""id"": ""03jvuys84fdg1""}, ""cspcs7s84fdg1"": {""status"": ""valid"", ""e"": ""Image"", ""m"": ""image/jpg"", ""p"": [{""y"": 19, ""x"": 108, ""u"": ""https://preview.redd.it/cspcs7s84fdg1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cf31b8e3fc868a8c541fa0fc88aaefd10d76bd73""}, {""y"": 38, ""x"": 216, ""u"": ""https://preview.redd.it/cspcs7s84fdg1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3688562fc90f27cc27381b485426866d1ced93e5""}, {""y"": 56, ""x"": 320, ""u"": ""https://preview.redd.it/cspcs7s84fdg1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb392b3ff863734354e092ac098b896e07f969eb""}, {""y"": 113, ""x"": 640, ""u"": ""https://preview.redd.it/cspcs7s84fdg1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=57314ddf66ad4b123b1662c1ca5646c0a41c0ae6""}, {""y"": 169, ""x"": 960, ""u"": ""https://preview.redd.it/cspcs7s84fdg1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=abec30773c110f637f8c6cbd202875bffc2c0bec""}], ""s"": {""y"": 181, ""x"": 1024, ""u"": ""https://preview.redd.it/cspcs7s84fdg1.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=2999c1ce707cd264fe7112bb1b38b9154f65c9b8""}, ""id"": ""cspcs7s84fdg1""}, ""fuj1kux84fdg1"": {""status"": ""valid"", ""e"": ""Image"", ""m"": ""image/jpg"", ""p"": [{""y"": 45, ""x"": 108, ""u"": ""https://preview.redd.it/fuj1kux84fdg1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b35bd86fdc890aa62d4d02164842b597d0e3c7c5""}, {""y"": 91, ""x"": 216, ""u"": ""https://preview.redd.it/fuj1kux84fdg1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0ecfa6b6829000ebf0d5ed98e9d9abb939c202c8""}, {""y"": 135, ""x"": 320, ""u"": ""https://preview.redd.it/fuj1kux84fdg1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0db35754eb4465534d0d429f143ffd7f604a48e1""}, {""y"": 271, ""x"": 640, ""u"": ""https://preview.redd.it/fuj1kux84fdg1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4aae4dd2251718f8579de1f1946220aa8ebca4bc""}, {""y"": 407, ""x"": 960, ""u"": ""https://preview.redd.it/fuj1kux84fdg1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1be841304d8a4879afcf93ffc3a0aa8bc8e9383c""}, {""y"": 458, ""x"": 1080, ""u"": ""https://preview.redd.it/fuj1kux84fdg1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ddbd3307f2dcde60ce7d4e163e1fc155466026d6""}], ""s"": {""y"": 458, ""x"": 1080, ""u"": ""https://preview.redd.it/fuj1kux84fdg1.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=3901b989b16694fc7cfa37d6456facfec32720c8""}, ""id"": ""fuj1kux84fdg1""}}, ""name"": ""t3_1qd696s"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.97, ""author_flair_background_color"": null, ""ups"": 250, ""domain"": ""reddit.com"", ""media_embed"": {}, ""thumbnail_width"": 140, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""gallery_data"": {""items"": [{""caption"": """", ""media_id"": ""if46fiq84fdg1"", ""id"": 840081581}, {""caption"": """", ""media_id"": ""cspcs7s84fdg1"", ""id"": 840081582}, {""caption"": """", ""media_id"": ""03jvuys84fdg1"", ""id"": 840081583}, {""caption"": """", ""media_id"": ""hcdrmut84fdg1"", ""id"": 840081584}, {""caption"": """", ""media_id"": ""xkqhaev84fdg1"", ""id"": 840081585}, {""caption"": """", ""media_id"": ""kmbdv3w84fdg1"", ""id"": 840081586}, {""caption"": """", ""media_id"": ""7htdqvw84fdg1"", ""id"": 840081587}, {""caption"": """", ""media_id"": ""fuj1kux84fdg1"", ""id"": 840081588}]}, ""link_flair_text"": ""Research"", ""can_mod_post"": false, ""score"": 250, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""https://b.thumbs.redditmedia.com/S251D6YJ_dV3rhcZWcFC2MYrU-me05kUpwPXlVwvZFs.jpg"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": false, ""subreddit_type"": ""public"", ""created"": 1768441406.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""total_awards_received"": 0, ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;h4&gt;TL;DR:&lt;/h4&gt;\n\n&lt;p&gt;The paper describes a mechanism that essentially turns the context window into a training dataset for a &amp;quot;fast weight&amp;quot; update loop:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Inner Loop:&lt;/strong&gt; The model runs a mini-gradient descent on the context during inference. It updates specific MLP layers to &amp;quot;learn&amp;quot; the current context.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Outer Loop:&lt;/strong&gt; The model&amp;#39;s initial weights are meta-learned during training to be &amp;quot;highly updateable&amp;quot; or optimized for this test-time adaptation&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;From the Paper:&lt;/strong&gt; &amp;quot;Overall, our empirical observations strongly indicate that TTT-E2E should produce the same trend as full attention for scaling with training compute in large-budget production runs.&amp;quot;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;h4&gt;Abstract:&lt;/h4&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture a Transformer with sliding-window attention. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;However, our model continues learning at test time via next-token prediction on the given context, compressing the context it reads into its weights.&lt;/strong&gt; In addition, we improve the model&amp;#39;s initialization for learning at test time via meta-learning at training time. Overall, our method, a form of Test-Time Training (TTT), is End-to-End (E2E) both at test time (via next-token prediction) and training time (via meta-learning), in contrast to previous forms. We conduct extensive experiments with a focus on scaling properties. &lt;/p&gt;\n\n&lt;p&gt;In particular, for 3B models trained with 164B tokens, our method (TTT-E2E) scales with context length in the same way as Transformer with full attention, while others, such as Mamba 2 and Gated DeltaNet, do not. However, similar to RNNs, TTT-E2E has constant inference latency regardless of context length, making it 2.7x faster than full attention for 128K context. &lt;strong&gt;Our code is publicly available.&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;hr/&gt;\n\n&lt;h4&gt;Layman&amp;#39;s Explanation:&lt;/h4&gt;\n\n&lt;p&gt;Think of this paper as solving the memory bottleneck by fundamentally changing how a model processes information. Imagine you are taking a massive open-book exam. &lt;/p&gt;\n\n&lt;p&gt;A standard Transformer (like GPT-4) is the student who frantically re-reads every single page of the textbook before answering every single question. This strategy guarantees they find the specific details (perfect recall), but as the textbook gets thicker, they get exponentially slower until they simply cannot finish the test in time. &lt;/p&gt;\n\n&lt;p&gt;On the other hand, alternatives like RNNs or Mamba try to summarize the entire textbook onto a single index card. They can answer questions instantly because they don&amp;#39;t have to look back at the book, but for long, complex subjects, they eventually run out of space on the card and start forgetting crucial information.&lt;/p&gt;\n\n&lt;p&gt;This new method, Test-Time Training (TTT), changes the paradigm from retrieving information to learning it on the fly. Instead of re-reading the book or summarizing it onto a card, the TTT model treats the context window as a dataset and actually trains itself on it in real-time. It performs a mini-gradient descent update on its own neural weights as it reads. &lt;strong&gt;This is equivalent to a student who reads the textbook and physically rewires their brain to master the subject matter before the test.&lt;/strong&gt; &lt;/p&gt;\n\n&lt;p&gt;Because the information is now compressed into the model&amp;#39;s actual intelligence (its weights) rather than a temporary cache, the model can answer questions instantly (matching the constant speed of the fast index-card models) but with the high accuracy and scaling capability of the slow, page-turning Transformers. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;This effectively decouples intelligence from memory costs, allowing for massive context lengths without the usual slowdown.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;h6&gt;Link to the Paper: &lt;a href=\""https://arxiv.org/pdf/2512.23675\""&gt;https://arxiv.org/pdf/2512.23675&lt;/a&gt;&lt;/h6&gt;\n\n&lt;hr/&gt;\n\n&lt;h6&gt;Link to the Open-Sourced Official Implementation of End-to-End Test Time Training for Long Context: &lt;a href=\""https://github.com/test-time-training/e2e\""&gt;https://github.com/test-time-training/e2e&lt;/a&gt;&lt;/h6&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""url_overridden_by_dest"": ""https://www.reddit.com/gallery/1qd696s"", ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""bb90e510-4e82-11e6-8635-0ee522e2349b"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""mod_note"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""num_reports"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#f1f10e"", ""id"": ""1qd696s"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""44th--Hokage"", ""discussion_type"": null, ""num_comments"": 20, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qd696s/nvidia_endtoend_testtime_training_for_long/"", ""stickied"": false, ""url"": ""https://www.reddit.com/gallery/1qd696s"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768441406.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qehwlu,MachineLearning,petroslamb,[D] Why Mamba rewrote its core algorithm and Microsoft abandoned RetNet,"Mamba-2 restructured its recurrence from parallel scans (10-20% Tensor Core utilization) to block-diagonal GEMMs (60-70%). The architecture bent to fit the silicon.

RetNet was published by Microsoft Research in July 2023 with promising results at 6.7B. Five months later, the same organization shipped Phi-2, a dense Transformer. Then Phi-3. Then Phi-4. The co-authors didn't bet on their own architecture.

I wrote an analysis of why this pattern keeps repeating. The short version: Transformers and NVIDIA GPUs co-evolved into a stable attractor. Breaking out requires clearing two reinforcing gates at once, hardware compatibility and institutional backing, and the gates make each other harder to pass. At frontier scale, no pure alternative has done it.

Essay has Tensor Core utilization numbers, analysis of alternative chip vendors, and three falsifiable predictions for 2028.",113,31,0.9,1768574865.0,/r/MachineLearning/comments/1qehwlu/d_why_mamba_rewrote_its_core_algorithm_and/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""Mamba-2 restructured its recurrence from parallel scans (10-20% Tensor Core utilization) to block-diagonal GEMMs (60-70%). The architecture bent to fit the silicon.\n\nRetNet was published by Microsoft Research in July 2023 with promising results at 6.7B. Five months later, the same organization shipped Phi-2, a dense Transformer. Then Phi-3. Then Phi-4. The co-authors didn't bet on their own architecture.\n\nI wrote an analysis of why this pattern keeps repeating. The short version: Transformers and NVIDIA GPUs co-evolved into a stable attractor. Breaking out requires clearing two reinforcing gates at once, hardware compatibility and institutional backing, and the gates make each other harder to pass. At frontier scale, no pure alternative has done it.\n\nEssay has Tensor Core utilization numbers, analysis of alternative chip vendors, and three falsifiable predictions for 2028."", ""author_fullname"": ""t2_13f22c"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] Why Mamba rewrote its core algorithm and Microsoft abandoned RetNet"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qehwlu"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.9, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 113, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Discussion"", ""can_mod_post"": false, ""score"": 113, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768574865.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;Mamba-2 restructured its recurrence from parallel scans (10-20% Tensor Core utilization) to block-diagonal GEMMs (60-70%). The architecture bent to fit the silicon.&lt;/p&gt;\n\n&lt;p&gt;RetNet was published by Microsoft Research in July 2023 with promising results at 6.7B. Five months later, the same organization shipped Phi-2, a dense Transformer. Then Phi-3. Then Phi-4. The co-authors didn&amp;#39;t bet on their own architecture.&lt;/p&gt;\n\n&lt;p&gt;I wrote an analysis of why this pattern keeps repeating. The short version: Transformers and NVIDIA GPUs co-evolved into a stable attractor. Breaking out requires clearing two reinforcing gates at once, hardware compatibility and institutional backing, and the gates make each other harder to pass. At frontier scale, no pure alternative has done it.&lt;/p&gt;\n\n&lt;p&gt;Essay has Tensor Core utilization numbers, analysis of alternative chip vendors, and three falsifiable predictions for 2028.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""15995904-19d4-11f0-b8c9-0eed6ea89bc1"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#26c4d9"", ""id"": ""1qehwlu"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""petroslamb"", ""discussion_type"": null, ""num_comments"": 31, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qehwlu/d_why_mamba_rewrote_its_core_algorithm_and/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qehwlu/d_why_mamba_rewrote_its_core_algorithm_and/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768574865.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qepc05,MachineLearning,RNRuben,[D] Burnout from the hiring process,"I've been interviewing for research (some engineering) interships for the last 2 months, and I think I'm at a point of mental exhaustion from constant rejections and wasted time.

For context, I just started my master’s at Waterloo, but I'm a research associate at one of the top labs in Europe. I have been doing research since my sophomore year. I did not start in ML, but over the last year and a half, I ended up in ML research, first in protein design and now in pretraining optimization.

I started applying for interships a few months ago, and after 10+ first-round interviews and endless OAs, I haven't landed any offers. Most of the companies that I've interviewed with were a mix of (non-FAANG) frontier AI companies, established deep tech startups, research labs of F100 companies, a couple non name startups, and a quant firm. I get past a few rounds, then get cut.

The feedback in general is that I'm not a good ""fit"" (a few companies told me I'm too researchy for a research engineer, another few were researching some niche stuff). And the next most common reason is that I failed the coding technical (I have no issue passing the research and ML theory technical interviews), but I think too slow for an engineer, and it's never the same type of questions (with one frontier company, I passed the research but failed the code review) and I'm not even counting OAs. Not a single one asked Leetcode or ML modelling; it's always some sort of a custom task that I have no prior experience with, so it's never the same stuff I can prepare.

I'm at a loss, to be honest. Every PhD and a bunch of master's students in our lab have interned at frontier companies, and I feel like a failure that, after so many interviews, I can't get an offer. Because of my CV (no lies), I don't have a problem getting interviews, but I can't seem to get an offer. I've tried applying for non-research and less competitive companies, but I get hit with ""not a good fit.""

I have 3 technicals next week, and tbh I know for a fact I'm not gonna pass 2 of them (too stupid to be a quant researcher) and the other is a 3rd round technical, but from the way he described it I don't think I'll be passing it (they're gonna throw a scientific simulation coding problem at me). And I still need to schedule one more between those 3, but I'm not sure why they even picked me, I don't do RL or robotics research. After so many days and hours spent preparing for each technical only to get cut, I mentally can't get myself to prepare for them anymore. It's always a new random format.

I'm severely burned out by this whole process, but time is running out. I love research, but I'm starting to hate the hiring process in this industry. Any advice on what to do?",108,43,0.92,1768590988.0,/r/MachineLearning/comments/1qepc05/d_burnout_from_the_hiring_process/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""I've been interviewing for research (some engineering) interships for the last 2 months, and I think I'm at a point of mental exhaustion from constant rejections and wasted time.\n\nFor context, I just started my master’s at Waterloo, but I'm a research associate at one of the top labs in Europe. I have been doing research since my sophomore year. I did not start in ML, but over the last year and a half, I ended up in ML research, first in protein design and now in pretraining optimization.\n\nI started applying for interships a few months ago, and after 10+ first-round interviews and endless OAs, I haven't landed any offers. Most of the companies that I've interviewed with were a mix of (non-FAANG) frontier AI companies, established deep tech startups, research labs of F100 companies, a couple non name startups, and a quant firm. I get past a few rounds, then get cut.\n\nThe feedback in general is that I'm not a good \""fit\"" (a few companies told me I'm too researchy for a research engineer, another few were researching some niche stuff). And the next most common reason is that I failed the coding technical (I have no issue passing the research and ML theory technical interviews), but I think too slow for an engineer, and it's never the same type of questions (with one frontier company, I passed the research but failed the code review) and I'm not even counting OAs. Not a single one asked Leetcode or ML modelling; it's always some sort of a custom task that I have no prior experience with, so it's never the same stuff I can prepare.\n\nI'm at a loss, to be honest. Every PhD and a bunch of master's students in our lab have interned at frontier companies, and I feel like a failure that, after so many interviews, I can't get an offer. Because of my CV (no lies), I don't have a problem getting interviews, but I can't seem to get an offer. I've tried applying for non-research and less competitive companies, but I get hit with \""not a good fit.\""\n\nI have 3 technicals next week, and tbh I know for a fact I'm not gonna pass 2 of them (too stupid to be a quant researcher) and the other is a 3rd round technical, but from the way he described it I don't think I'll be passing it (they're gonna throw a scientific simulation coding problem at me). And I still need to schedule one more between those 3, but I'm not sure why they even picked me, I don't do RL or robotics research. After so many days and hours spent preparing for each technical only to get cut, I mentally can't get myself to prepare for them anymore. It's always a new random format.\n\nI'm severely burned out by this whole process, but time is running out. I love research, but I'm starting to hate the hiring process in this industry. Any advice on what to do?"", ""author_fullname"": ""t2_29wajc4v"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] Burnout from the hiring process"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qepc05"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.92, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 108, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Discussion"", ""can_mod_post"": false, ""score"": 108, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": 1768592481.0, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768590988.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;I&amp;#39;ve been interviewing for research (some engineering) interships for the last 2 months, and I think I&amp;#39;m at a point of mental exhaustion from constant rejections and wasted time.&lt;/p&gt;\n\n&lt;p&gt;For context, I just started my master’s at Waterloo, but I&amp;#39;m a research associate at one of the top labs in Europe. I have been doing research since my sophomore year. I did not start in ML, but over the last year and a half, I ended up in ML research, first in protein design and now in pretraining optimization.&lt;/p&gt;\n\n&lt;p&gt;I started applying for interships a few months ago, and after 10+ first-round interviews and endless OAs, I haven&amp;#39;t landed any offers. Most of the companies that I&amp;#39;ve interviewed with were a mix of (non-FAANG) frontier AI companies, established deep tech startups, research labs of F100 companies, a couple non name startups, and a quant firm. I get past a few rounds, then get cut.&lt;/p&gt;\n\n&lt;p&gt;The feedback in general is that I&amp;#39;m not a good &amp;quot;fit&amp;quot; (a few companies told me I&amp;#39;m too researchy for a research engineer, another few were researching some niche stuff). And the next most common reason is that I failed the coding technical (I have no issue passing the research and ML theory technical interviews), but I think too slow for an engineer, and it&amp;#39;s never the same type of questions (with one frontier company, I passed the research but failed the code review) and I&amp;#39;m not even counting OAs. Not a single one asked Leetcode or ML modelling; it&amp;#39;s always some sort of a custom task that I have no prior experience with, so it&amp;#39;s never the same stuff I can prepare.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m at a loss, to be honest. Every PhD and a bunch of master&amp;#39;s students in our lab have interned at frontier companies, and I feel like a failure that, after so many interviews, I can&amp;#39;t get an offer. Because of my CV (no lies), I don&amp;#39;t have a problem getting interviews, but I can&amp;#39;t seem to get an offer. I&amp;#39;ve tried applying for non-research and less competitive companies, but I get hit with &amp;quot;not a good fit.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I have 3 technicals next week, and tbh I know for a fact I&amp;#39;m not gonna pass 2 of them (too stupid to be a quant researcher) and the other is a 3rd round technical, but from the way he described it I don&amp;#39;t think I&amp;#39;ll be passing it (they&amp;#39;re gonna throw a scientific simulation coding problem at me). And I still need to schedule one more between those 3, but I&amp;#39;m not sure why they even picked me, I don&amp;#39;t do RL or robotics research. After so many days and hours spent preparing for each technical only to get cut, I mentally can&amp;#39;t get myself to prepare for them anymore. It&amp;#39;s always a new random format.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m severely burned out by this whole process, but time is running out. I love research, but I&amp;#39;m starting to hate the hiring process in this industry. Any advice on what to do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""15995904-19d4-11f0-b8c9-0eed6ea89bc1"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#26c4d9"", ""id"": ""1qepc05"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""RNRuben"", ""discussion_type"": null, ""num_comments"": 43, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qepc05/d_burnout_from_the_hiring_process/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qepc05/d_burnout_from_the_hiring_process/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768590988.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qh9sg5,MachineLearning,Training-Adeptness57,[R] Is Leetcode still relevant for research scientist interviews?,"Hello everybody,

I’m at my third (and last year) of my phd in computer vision, and I want to start preparing for technical interviews. What I want to do is work as a research scientist, preferably at companies like Meta. In terms of publications and research knowledge I think I have a quite decent profile with 4 papers at A\* conferences. However I have heard that the coding interviews can be quite thought even for research scientist jobs. So I’m wondering if practicing with leetcode still relevant or is there other alternatives?

Thanks!",91,40,0.93,1768842083.0,/r/MachineLearning/comments/1qh9sg5/r_is_leetcode_still_relevant_for_research/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""Hello everybody,\n\nI’m at my third (and last year) of my phd in computer vision, and I want to start preparing for technical interviews. What I want to do is work as a research scientist, preferably at companies like Meta. In terms of publications and research knowledge I think I have a quite decent profile with 4 papers at A\\* conferences. However I have heard that the coding interviews can be quite thought even for research scientist jobs. So I’m wondering if practicing with leetcode still relevant or is there other alternatives?\n\nThanks!"", ""author_fullname"": ""t2_m6jxh0t3"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[R] Is Leetcode still relevant for research scientist interviews?"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": ""three"", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qh9sg5"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.93, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 91, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Research"", ""can_mod_post"": false, ""score"": 91, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": 1768842828.0, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768842083.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;Hello everybody,&lt;/p&gt;\n\n&lt;p&gt;I’m at my third (and last year) of my phd in computer vision, and I want to start preparing for technical interviews. What I want to do is work as a research scientist, preferably at companies like Meta. In terms of publications and research knowledge I think I have a quite decent profile with 4 papers at A* conferences. However I have heard that the coding interviews can be quite thought even for research scientist jobs. So I’m wondering if practicing with leetcode still relevant or is there other alternatives?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""bb90e510-4e82-11e6-8635-0ee522e2349b"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#f1f10e"", ""id"": ""1qh9sg5"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""Training-Adeptness57"", ""discussion_type"": null, ""num_comments"": 40, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qh9sg5/r_is_leetcode_still_relevant_for_research/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qh9sg5/r_is_leetcode_still_relevant_for_research/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768842083.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qcxhgw,MachineLearning,exhorder72,[P] my shot at a DeepSeek style moe on a single rtx 5090,"I know most will wonder why I’m wasting my time training at only 19k tok a sec. It’s because I can. I’m doing this in my living room in my spare time. 0 formal ML experience. The absurd amount I’ve learned in the last few months made me realize I really picked the wrong career.

My Mixture of Experts is 2.36B parameter with 8 routed experts plus a shared expert using top-2 routing. Attention is Grouped Query Attention with QK-normalization and RoPE positional embeddings. All feed-forward layers use SwiGLU activation with RMSNorm throughout. Load balancing follows DeepSeek V3’s auxiliary-loss-free approach using bias-based routing. I monitor coefficient of variation and maximum violation per step.

Training runs on TorchAO FP8 quantization with the Muon optimizer and a multi-stage learning rate schedule (warmup, constant, cosine decay). The backend is optimized for Blackwell architecture with cuBLASLt.

The data pipeline implements MeCo (Metadata Conditioning then Cooldown) with ledger-based deterministic sampling. I have document-aware attention masking and cross-document loss masking but was disabled for the initial MeCo run. I have since disabled MeCo and curated a clean corpus with no tagging of any kind. MeCo worked but it worked too well and with only 8 experts, it became very problematic.

My two biggest early mistakes were not using symmetric router initialization (std=0.006) and not having a dense first layer. Cost me a lot of time and sleep. So what did I do? I cheated. I used aux loss of .003 snd ema smoothing at the beginning. I just didn’t know better. I paid a price later on for that.

DO NOT use router scaling on a small MoE. DeepSeek used 2.5. Kimi K2 used 2.446. I tried 1.2 and it was horribly unstable and violation blew up to over .500.

24 batch 6 Grad LR 3e-4 AdamW+Muon Scaled. Bias .001 Aux .0001. I update every step.

As of yesterday: 2026-01-13 20:53:06 step 41915 | lr 3.00e-04 | loss 1.8867 | gnorm 0.13 | 19,415 tok/s (ema 19,553) | 75.9s/5 steps | cv 0.022 | bias -0.001708±0.179996 | rel_max=0.036 maxvio=0.027 ent=1.203 applied=True | seq_aux 2.444 2026-01-13 20:54:20     [moe] token counts: [150018, 148422, 155402, 147966, 145236, 146724, 144358, 141522] 2026-01-13 20:54:20 step 41920 | lr 3.00e-04 | loss 1.9263 | gnorm 0.13 | 20,102 tok/s (ema 19,828) | 73.4s/5 steps | cv 0.026 | bias -0.001708±0.179920 | rel_max=0.054 maxvio=0.054 ent=1.211 applied=True | seq_aux 2.515

I got a long ways to go :)

I’ll gladly answer any question. No gate keeping here. ",80,29,0.95,1768420405.0,/r/MachineLearning/comments/1qcxhgw/p_my_shot_at_a_deepseek_style_moe_on_a_single_rtx/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""I know most will wonder why I’m wasting my time training at only 19k tok a sec. It’s because I can. I’m doing this in my living room in my spare time. 0 formal ML experience. The absurd amount I’ve learned in the last few months made me realize I really picked the wrong career.\n\nMy Mixture of Experts is 2.36B parameter with 8 routed experts plus a shared expert using top-2 routing. Attention is Grouped Query Attention with QK-normalization and RoPE positional embeddings. All feed-forward layers use SwiGLU activation with RMSNorm throughout. Load balancing follows DeepSeek V3’s auxiliary-loss-free approach using bias-based routing. I monitor coefficient of variation and maximum violation per step.\n\nTraining runs on TorchAO FP8 quantization with the Muon optimizer and a multi-stage learning rate schedule (warmup, constant, cosine decay). The backend is optimized for Blackwell architecture with cuBLASLt.\n\nThe data pipeline implements MeCo (Metadata Conditioning then Cooldown) with ledger-based deterministic sampling. I have document-aware attention masking and cross-document loss masking but was disabled for the initial MeCo run. I have since disabled MeCo and curated a clean corpus with no tagging of any kind. MeCo worked but it worked too well and with only 8 experts, it became very problematic.\n\nMy two biggest early mistakes were not using symmetric router initialization (std=0.006) and not having a dense first layer. Cost me a lot of time and sleep. So what did I do? I cheated. I used aux loss of .003 snd ema smoothing at the beginning. I just didn’t know better. I paid a price later on for that.\n\nDO NOT use router scaling on a small MoE. DeepSeek used 2.5. Kimi K2 used 2.446. I tried 1.2 and it was horribly unstable and violation blew up to over .500.\n\n24 batch 6 Grad LR 3e-4 AdamW+Muon Scaled. Bias .001 Aux .0001. I update every step.\n\nAs of yesterday: 2026-01-13 20:53:06 step 41915 | lr 3.00e-04 | loss 1.8867 | gnorm 0.13 | 19,415 tok/s (ema 19,553) | 75.9s/5 steps | cv 0.022 | bias -0.001708±0.179996 | rel_max=0.036 maxvio=0.027 ent=1.203 applied=True | seq_aux 2.444 2026-01-13 20:54:20     [moe] token counts: [150018, 148422, 155402, 147966, 145236, 146724, 144358, 141522] 2026-01-13 20:54:20 step 41920 | lr 3.00e-04 | loss 1.9263 | gnorm 0.13 | 20,102 tok/s (ema 19,828) | 73.4s/5 steps | cv 0.026 | bias -0.001708±0.179920 | rel_max=0.054 maxvio=0.054 ent=1.211 applied=True | seq_aux 2.515\n\nI got a long ways to go :)\n\nI’ll gladly answer any question. No gate keeping here. "", ""author_fullname"": ""t2_jttc1"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[P] my shot at a DeepSeek style moe on a single rtx 5090"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qcxhgw"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.95, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 80, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Project"", ""can_mod_post"": false, ""score"": 80, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768420405.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;I know most will wonder why I’m wasting my time training at only 19k tok a sec. It’s because I can. I’m doing this in my living room in my spare time. 0 formal ML experience. The absurd amount I’ve learned in the last few months made me realize I really picked the wrong career.&lt;/p&gt;\n\n&lt;p&gt;My Mixture of Experts is 2.36B parameter with 8 routed experts plus a shared expert using top-2 routing. Attention is Grouped Query Attention with QK-normalization and RoPE positional embeddings. All feed-forward layers use SwiGLU activation with RMSNorm throughout. Load balancing follows DeepSeek V3’s auxiliary-loss-free approach using bias-based routing. I monitor coefficient of variation and maximum violation per step.&lt;/p&gt;\n\n&lt;p&gt;Training runs on TorchAO FP8 quantization with the Muon optimizer and a multi-stage learning rate schedule (warmup, constant, cosine decay). The backend is optimized for Blackwell architecture with cuBLASLt.&lt;/p&gt;\n\n&lt;p&gt;The data pipeline implements MeCo (Metadata Conditioning then Cooldown) with ledger-based deterministic sampling. I have document-aware attention masking and cross-document loss masking but was disabled for the initial MeCo run. I have since disabled MeCo and curated a clean corpus with no tagging of any kind. MeCo worked but it worked too well and with only 8 experts, it became very problematic.&lt;/p&gt;\n\n&lt;p&gt;My two biggest early mistakes were not using symmetric router initialization (std=0.006) and not having a dense first layer. Cost me a lot of time and sleep. So what did I do? I cheated. I used aux loss of .003 snd ema smoothing at the beginning. I just didn’t know better. I paid a price later on for that.&lt;/p&gt;\n\n&lt;p&gt;DO NOT use router scaling on a small MoE. DeepSeek used 2.5. Kimi K2 used 2.446. I tried 1.2 and it was horribly unstable and violation blew up to over .500.&lt;/p&gt;\n\n&lt;p&gt;24 batch 6 Grad LR 3e-4 AdamW+Muon Scaled. Bias .001 Aux .0001. I update every step.&lt;/p&gt;\n\n&lt;p&gt;As of yesterday: 2026-01-13 20:53:06 step 41915 | lr 3.00e-04 | loss 1.8867 | gnorm 0.13 | 19,415 tok/s (ema 19,553) | 75.9s/5 steps | cv 0.022 | bias -0.001708±0.179996 | rel_max=0.036 maxvio=0.027 ent=1.203 applied=True | seq_aux 2.444 2026-01-13 20:54:20     [moe] token counts: [150018, 148422, 155402, 147966, 145236, 146724, 144358, 141522] 2026-01-13 20:54:20 step 41920 | lr 3.00e-04 | loss 1.9263 | gnorm 0.13 | 20,102 tok/s (ema 19,828) | 73.4s/5 steps | cv 0.026 | bias -0.001708±0.179920 | rel_max=0.054 maxvio=0.054 ent=1.211 applied=True | seq_aux 2.515&lt;/p&gt;\n\n&lt;p&gt;I got a long ways to go :)&lt;/p&gt;\n\n&lt;p&gt;I’ll gladly answer any question. No gate keeping here. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""c6dea51c-19d3-11f0-81a2-deb9d8e21ccb"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#7d659a"", ""id"": ""1qcxhgw"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""exhorder72"", ""discussion_type"": null, ""num_comments"": 29, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qcxhgw/p_my_shot_at_a_deepseek_style_moe_on_a_single_rtx/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qcxhgw/p_my_shot_at_a_deepseek_style_moe_on_a_single_rtx/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768420405.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qbu8wp,MachineLearning,Affectionate_Use9936,[D] I see more people trying to explain mHC than build it,"This really irks me for some reason but there's like 10,000 explanations for mHC online while the only instance of someone actually trying to explore mHC in code is a single github repo (props to the repo).

I just want to be able to implement it and plug it into existing projects. I don't need yet another analogy for why a cat won't fall off a cliff the ground isn't tipped over.

This reminds me of my physics days when I'd see a constant stream of gurus explain some philosophy behind energy and the universe when they can't even take an eigenvalue. Like stay in your lane buddy. Or I guess multiple lanes...",70,17,0.89,1768318042.0,/r/MachineLearning/comments/1qbu8wp/d_i_see_more_people_trying_to_explain_mhc_than/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""This really irks me for some reason but there's like 10,000 explanations for mHC online while the only instance of someone actually trying to explore mHC in code is a single github repo (props to the repo).\n\nI just want to be able to implement it and plug it into existing projects. I don't need yet another analogy for why a cat won't fall off a cliff the ground isn't tipped over.\n\nThis reminds me of my physics days when I'd see a constant stream of gurus explain some philosophy behind energy and the universe when they can't even take an eigenvalue. Like stay in your lane buddy. Or I guess multiple lanes..."", ""author_fullname"": ""t2_114qkrc94a"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] I see more people trying to explain mHC than build it"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qbu8wp"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.89, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 70, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Discussion"", ""can_mod_post"": false, ""score"": 70, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""author_cakeday"": true, ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768318042.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;This really irks me for some reason but there&amp;#39;s like 10,000 explanations for mHC online while the only instance of someone actually trying to explore mHC in code is a single github repo (props to the repo).&lt;/p&gt;\n\n&lt;p&gt;I just want to be able to implement it and plug it into existing projects. I don&amp;#39;t need yet another analogy for why a cat won&amp;#39;t fall off a cliff the ground isn&amp;#39;t tipped over.&lt;/p&gt;\n\n&lt;p&gt;This reminds me of my physics days when I&amp;#39;d see a constant stream of gurus explain some philosophy behind energy and the universe when they can&amp;#39;t even take an eigenvalue. Like stay in your lane buddy. Or I guess multiple lanes...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""15995904-19d4-11f0-b8c9-0eed6ea89bc1"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#26c4d9"", ""id"": ""1qbu8wp"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""Affectionate_Use9936"", ""discussion_type"": null, ""num_comments"": 17, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qbu8wp/d_i_see_more_people_trying_to_explain_mhc_than/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qbu8wp/d_i_see_more_people_trying_to_explain_mhc_than/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768318042.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qeakhz,MachineLearning,Different_Case_6484,[R] China just released first SOTA multimodal model trained entirely on domestic chips,"Zhipu AI and Huawei just dropped GLM-Image, and the technical details are interesting.

First multimodal model trained completely on Chinese chips (Huawei Ascend 910) from data preprocessing to full scale training. They're using a hybrid architecture combining autoregressive + diffusion decoder.

What stands out is the Chinese text rendering. It consistently ranks first among open source models for complex text generation, especially handling Chinese characters which most models struggle with.

Native support for 1024 to 2048 resolution at any aspect ratio without additional training. API pricing is 0.1 yuan per image (roughly $0.014).

The model handles both text to image and image to image generation in a single model. GitHub and Hugging Face repos are already up.

This is significant because it proves you can train frontier models without relying on Nvidia hardware. The compute efficiency numbers they're claiming are 60% better than H200 for tokens per joule.

Whether those benchmarks hold up in practice remains to be seen but the fact they pulled this off on domestic hardware is noteworthy.

Edit: For anyone testing this, X-Design also handles multilingual text rendering well. Been comparing outputs and both handle complex layouts better than DALL-E 3.

",66,7,0.83,1768552052.0,/r/MachineLearning/comments/1qeakhz/r_china_just_released_first_sota_multimodal_model/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""Zhipu AI and Huawei just dropped GLM-Image, and the technical details are interesting.\n\nFirst multimodal model trained completely on Chinese chips (Huawei Ascend 910) from data preprocessing to full scale training. They're using a hybrid architecture combining autoregressive + diffusion decoder.\n\nWhat stands out is the Chinese text rendering. It consistently ranks first among open source models for complex text generation, especially handling Chinese characters which most models struggle with.\n\nNative support for 1024 to 2048 resolution at any aspect ratio without additional training. API pricing is 0.1 yuan per image (roughly $0.014).\n\nThe model handles both text to image and image to image generation in a single model. GitHub and Hugging Face repos are already up.\n\nThis is significant because it proves you can train frontier models without relying on Nvidia hardware. The compute efficiency numbers they're claiming are 60% better than H200 for tokens per joule.\n\nWhether those benchmarks hold up in practice remains to be seen but the fact they pulled this off on domestic hardware is noteworthy.\n\nEdit: For anyone testing this, X-Design also handles multilingual text rendering well. Been comparing outputs and both handle complex layouts better than DALL-E 3.\n\n"", ""author_fullname"": ""t2_1tdtlkokq2"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[R] China just released first SOTA multimodal model trained entirely on domestic chips"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": ""three"", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qeakhz"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.83, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 66, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Research"", ""can_mod_post"": false, ""score"": 66, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": 1768794675.0, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768552052.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;Zhipu AI and Huawei just dropped GLM-Image, and the technical details are interesting.&lt;/p&gt;\n\n&lt;p&gt;First multimodal model trained completely on Chinese chips (Huawei Ascend 910) from data preprocessing to full scale training. They&amp;#39;re using a hybrid architecture combining autoregressive + diffusion decoder.&lt;/p&gt;\n\n&lt;p&gt;What stands out is the Chinese text rendering. It consistently ranks first among open source models for complex text generation, especially handling Chinese characters which most models struggle with.&lt;/p&gt;\n\n&lt;p&gt;Native support for 1024 to 2048 resolution at any aspect ratio without additional training. API pricing is 0.1 yuan per image (roughly $0.014).&lt;/p&gt;\n\n&lt;p&gt;The model handles both text to image and image to image generation in a single model. GitHub and Hugging Face repos are already up.&lt;/p&gt;\n\n&lt;p&gt;This is significant because it proves you can train frontier models without relying on Nvidia hardware. The compute efficiency numbers they&amp;#39;re claiming are 60% better than H200 for tokens per joule.&lt;/p&gt;\n\n&lt;p&gt;Whether those benchmarks hold up in practice remains to be seen but the fact they pulled this off on domestic hardware is noteworthy.&lt;/p&gt;\n\n&lt;p&gt;Edit: For anyone testing this, X-Design also handles multilingual text rendering well. Been comparing outputs and both handle complex layouts better than DALL-E 3.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""bb90e510-4e82-11e6-8635-0ee522e2349b"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#f1f10e"", ""id"": ""1qeakhz"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""Different_Case_6484"", ""discussion_type"": null, ""num_comments"": 7, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qeakhz/r_china_just_released_first_sota_multimodal_model/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qeakhz/r_china_just_released_first_sota_multimodal_model/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768552052.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qbtbfb,MachineLearning,44seconds,"[R] Vision Transformers with Self-Distilled Registers, NeurIPS 2025","So sharing some of our work we published at NeurIPS 2025 as a Spotlight.

Weights and code are public (see ArXiv).

TL;DR: Vision Transformers typically have artifacts in their ***dense features***. While the exact reason is unknown, there is consensus that adding so called ""***register***"" tokens mitigates this issue. These tokens participate in the self-attention process, but are not used for the output.

When introduced with DINOv2 models in ICLR 2024, this requires vision transformers to be trained from scratch -- which obviously most people cannot afford.

We show that you can actually get the benefits of registers pretty cheaply ***with existing pre-trained models*** without ANY labeled images. You can leverage the semantic invariance of images under shift &amp; left-right flip (most natural images, obviously don't flip images that contain text). We simply randomly augment the image multiple times, pad the borders with white, and un-shift/un-flip the dense features, and average over augmentations to use as a distillation target.

Surprisingly this extremely simple approach (Post Hoc Registers, PH-Reg) ***improves dense features for segmentation and depth across all datasets*** compared to both the student and the non-augmented teacher.

Our results are better than traditional attention modifications (MaskCLIP -- ECCV 22, SCLIP -- ECCV 24, ClearCLIP -- ECCV 24, NACLIP -- WACV 25), and much cheaper than *Denoising Vision Transformers* since we don't need to utilize neural fields. Our results introduce minimal additional parameters compared to the original model.   
",60,8,0.95,1768315875.0,/r/MachineLearning/comments/1qbtbfb/r_vision_transformers_with_selfdistilled/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""So sharing some of our work we published at NeurIPS 2025 as a Spotlight.\n\nWeights and code are public (see ArXiv).\n\nTL;DR: Vision Transformers typically have artifacts in their ***dense features***. While the exact reason is unknown, there is consensus that adding so called \""***register***\"" tokens mitigates this issue. These tokens participate in the self-attention process, but are not used for the output.\n\nWhen introduced with DINOv2 models in ICLR 2024, this requires vision transformers to be trained from scratch -- which obviously most people cannot afford.\n\nWe show that you can actually get the benefits of registers pretty cheaply ***with existing pre-trained models*** without ANY labeled images. You can leverage the semantic invariance of images under shift &amp; left-right flip (most natural images, obviously don't flip images that contain text). We simply randomly augment the image multiple times, pad the borders with white, and un-shift/un-flip the dense features, and average over augmentations to use as a distillation target.\n\nSurprisingly this extremely simple approach (Post Hoc Registers, PH-Reg) ***improves dense features for segmentation and depth across all datasets*** compared to both the student and the non-augmented teacher.\n\nOur results are better than traditional attention modifications (MaskCLIP -- ECCV 22, SCLIP -- ECCV 24, ClearCLIP -- ECCV 24, NACLIP -- WACV 25), and much cheaper than *Denoising Vision Transformers* since we don't need to utilize neural fields. Our results introduce minimal additional parameters compared to the original model.   \n"", ""author_fullname"": ""t2_nm52x"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[R] Vision Transformers with Self-Distilled Registers, NeurIPS 2025"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": ""three"", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qbtbfb"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.95, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 60, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Research"", ""can_mod_post"": false, ""score"": 60, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""default"", ""edited"": 1768317011.0, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": false, ""mod_note"": null, ""created"": 1768315875.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""arxiv.org"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;So sharing some of our work we published at NeurIPS 2025 as a Spotlight.&lt;/p&gt;\n\n&lt;p&gt;Weights and code are public (see ArXiv).&lt;/p&gt;\n\n&lt;p&gt;TL;DR: Vision Transformers typically have artifacts in their &lt;strong&gt;&lt;em&gt;dense features&lt;/em&gt;&lt;/strong&gt;. While the exact reason is unknown, there is consensus that adding so called &amp;quot;&lt;strong&gt;&lt;em&gt;register&lt;/em&gt;&lt;/strong&gt;&amp;quot; tokens mitigates this issue. These tokens participate in the self-attention process, but are not used for the output.&lt;/p&gt;\n\n&lt;p&gt;When introduced with DINOv2 models in ICLR 2024, this requires vision transformers to be trained from scratch -- which obviously most people cannot afford.&lt;/p&gt;\n\n&lt;p&gt;We show that you can actually get the benefits of registers pretty cheaply &lt;strong&gt;&lt;em&gt;with existing pre-trained models&lt;/em&gt;&lt;/strong&gt; without ANY labeled images. You can leverage the semantic invariance of images under shift &amp;amp; left-right flip (most natural images, obviously don&amp;#39;t flip images that contain text). We simply randomly augment the image multiple times, pad the borders with white, and un-shift/un-flip the dense features, and average over augmentations to use as a distillation target.&lt;/p&gt;\n\n&lt;p&gt;Surprisingly this extremely simple approach (Post Hoc Registers, PH-Reg) &lt;strong&gt;&lt;em&gt;improves dense features for segmentation and depth across all datasets&lt;/em&gt;&lt;/strong&gt; compared to both the student and the non-augmented teacher.&lt;/p&gt;\n\n&lt;p&gt;Our results are better than traditional attention modifications (MaskCLIP -- ECCV 22, SCLIP -- ECCV 24, ClearCLIP -- ECCV 24, NACLIP -- WACV 25), and much cheaper than &lt;em&gt;Denoising Vision Transformers&lt;/em&gt; since we don&amp;#39;t need to utilize neural fields. Our results introduce minimal additional parameters compared to the original model.   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""url_overridden_by_dest"": ""https://arxiv.org/abs/2505.21501"", ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""bb90e510-4e82-11e6-8635-0ee522e2349b"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#f1f10e"", ""id"": ""1qbtbfb"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""44seconds"", ""discussion_type"": null, ""num_comments"": 8, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qbtbfb/r_vision_transformers_with_selfdistilled/"", ""stickied"": false, ""url"": ""https://arxiv.org/abs/2505.21501"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768315875.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qg5pa9,MachineLearning,reutococco,[D] ICML26 new review policies,"ICML26 introduced a review type selection, where the author can decide whether LLMs can be used during their paper review, according to these two policies:

* **Policy A (Conservative):** Use of LLMs for reviewing is strictly prohibited.  
* **Policy B (Permissive):** 
   * ***Allowed***: Use of LLMs to help understand the paper and related works, and polish reviews. Submissions can be fed to privacy-compliant\* LLMs. 
   * ***Not allowed***: Ask LLMs about strengths/weaknesses, ask to suggest key points for the review, suggest an outline for the review, or write the full review *\*By “privacy-compliant”, we refer to LLM tools that do not use logged data for training and that place limits on data retention. This includes enterprise/institutional subscriptions to LLM APIs, consumer subscriptions with an explicit opt-out from training, and self-hosted LLMs. (We understand that this is an oversimplification.)*

I'm struggling to decide which one to select, any suggestions?",51,23,0.95,1768733691.0,/r/MachineLearning/comments/1qg5pa9/d_icml26_new_review_policies/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""ICML26 introduced a review type selection, where the author can decide whether LLMs can be used during their paper review, according to these two policies:\n\n* **Policy A (Conservative):** Use of LLMs for reviewing is strictly prohibited.  \n* **Policy B (Permissive):** \n   * ***Allowed***: Use of LLMs to help understand the paper and related works, and polish reviews. Submissions can be fed to privacy-compliant\\* LLMs. \n   * ***Not allowed***: Ask LLMs about strengths/weaknesses, ask to suggest key points for the review, suggest an outline for the review, or write the full review *\\*By “privacy-compliant”, we refer to LLM tools that do not use logged data for training and that place limits on data retention. This includes enterprise/institutional subscriptions to LLM APIs, consumer subscriptions with an explicit opt-out from training, and self-hosted LLMs. (We understand that this is an oversimplification.)*\n\nI'm struggling to decide which one to select, any suggestions?"", ""author_fullname"": ""t2_6b7we2ye"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] ICML26 new review policies"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": ""three"", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qg5pa9"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.95, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 51, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Research"", ""can_mod_post"": false, ""score"": 51, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768733691.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;ICML26 introduced a review type selection, where the author can decide whether LLMs can be used during their paper review, according to these two policies:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Policy A (Conservative):&lt;/strong&gt; Use of LLMs for reviewing is strictly prohibited.  &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Policy B (Permissive):&lt;/strong&gt; \n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Allowed&lt;/em&gt;&lt;/strong&gt;: Use of LLMs to help understand the paper and related works, and polish reviews. Submissions can be fed to privacy-compliant* LLMs. &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;&lt;em&gt;Not allowed&lt;/em&gt;&lt;/strong&gt;: Ask LLMs about strengths/weaknesses, ask to suggest key points for the review, suggest an outline for the review, or write the full review &lt;em&gt;\\&lt;/em&gt;By “privacy-compliant”, we refer to LLM tools that do not use logged data for training and that place limits on data retention. This includes enterprise/institutional subscriptions to LLM APIs, consumer subscriptions with an explicit opt-out from training, and self-hosted LLMs. (We understand that this is an oversimplification.)*&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m struggling to decide which one to select, any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""bb90e510-4e82-11e6-8635-0ee522e2349b"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#f1f10e"", ""id"": ""1qg5pa9"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""reutococco"", ""discussion_type"": null, ""num_comments"": 23, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qg5pa9/d_icml26_new_review_policies/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qg5pa9/d_icml26_new_review_policies/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768733691.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qe1z90,MachineLearning,ApprehensiveEgg5201,[R] Is it possible for a high school student to publish multiple papers at top conferences within a year?,"I recently came across the [Google Scholar profile](https://scholar.google.com/citations?hl=en&amp;user=pCrKkUQAAAAJ&amp;view_op=list_works&amp;sortby=pubdate) of a high school student and was quite astonished by the strength of his publication record. Even more strikingly, he is also serving as a reviewer for ICLR and AISTATS.",45,23,0.7,1768525976.0,/r/MachineLearning/comments/1qe1z90/r_is_it_possible_for_a_high_school_student_to/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""I recently came across the [Google Scholar profile](https://scholar.google.com/citations?hl=en&amp;user=pCrKkUQAAAAJ&amp;view_op=list_works&amp;sortby=pubdate) of a high school student and was quite astonished by the strength of his publication record. Even more strikingly, he is also serving as a reviewer for ICLR and AISTATS."", ""author_fullname"": ""t2_2tpqnujw"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[R] Is it possible for a high school student to publish multiple papers at top conferences within a year?"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": ""three"", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qe1z90"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.7, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 45, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Research"", ""can_mod_post"": false, ""score"": 45, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768525976.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;I recently came across the &lt;a href=\""https://scholar.google.com/citations?hl=en&amp;amp;user=pCrKkUQAAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate\""&gt;Google Scholar profile&lt;/a&gt; of a high school student and was quite astonished by the strength of his publication record. Even more strikingly, he is also serving as a reviewer for ICLR and AISTATS.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""bb90e510-4e82-11e6-8635-0ee522e2349b"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#f1f10e"", ""id"": ""1qe1z90"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""ApprehensiveEgg5201"", ""discussion_type"": null, ""num_comments"": 23, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qe1z90/r_is_it_possible_for_a_high_school_student_to/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qe1z90/r_is_it_possible_for_a_high_school_student_to/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768525976.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qf80mh,MachineLearning,randmusr66,[P] Progressive coding exercises for transformer internals,"For a while I've been looking for a good format to practice implementing ML algorithms. LeetCode feels too disconnected from real work, but in actual projects you just use existing libraries. What worked for me was breaking real algorithms into progressive steps and implementing them piece by piece.

I've been using this approach for myself, and recently decided to clean up some of it with tests and hints in case others find it useful. Currently covers: attention, BPE tokenization, beam search variants, and RoPE.

Curious if others have found similar formats helpful, or what primitives would be worth adding.",42,6,0.95,1768638804.0,/r/MachineLearning/comments/1qf80mh/p_progressive_coding_exercises_for_transformer/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""For a while I've been looking for a good format to practice implementing ML algorithms. LeetCode feels too disconnected from real work, but in actual projects you just use existing libraries. What worked for me was breaking real algorithms into progressive steps and implementing them piece by piece.\n\nI've been using this approach for myself, and recently decided to clean up some of it with tests and hints in case others find it useful. Currently covers: attention, BPE tokenization, beam search variants, and RoPE.\n\nCurious if others have found similar formats helpful, or what primitives would be worth adding."", ""author_fullname"": ""t2_qxh6f3le"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[P] Progressive coding exercises for transformer internals"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qf80mh"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.95, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 42, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Project"", ""can_mod_post"": false, ""score"": 42, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""default"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": false, ""mod_note"": null, ""created"": 1768638804.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""github.com"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;For a while I&amp;#39;ve been looking for a good format to practice implementing ML algorithms. LeetCode feels too disconnected from real work, but in actual projects you just use existing libraries. What worked for me was breaking real algorithms into progressive steps and implementing them piece by piece.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using this approach for myself, and recently decided to clean up some of it with tests and hints in case others find it useful. Currently covers: attention, BPE tokenization, beam search variants, and RoPE.&lt;/p&gt;\n\n&lt;p&gt;Curious if others have found similar formats helpful, or what primitives would be worth adding.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""url_overridden_by_dest"": ""https://github.com/cortwave/ml-engineering-practice"", ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""c6dea51c-19d3-11f0-81a2-deb9d8e21ccb"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#7d659a"", ""id"": ""1qf80mh"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""randmusr66"", ""discussion_type"": null, ""num_comments"": 6, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qf80mh/p_progressive_coding_exercises_for_transformer/"", ""stickied"": false, ""url"": ""https://github.com/cortwave/ml-engineering-practice"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768638804.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qeips6,MachineLearning,Financial-Panda6581,[D] ICASSP 2026 Results,"It looks like ICASSP 2026 decisions may already be accessible.

If you can log in to the following link and successfully send an invitation email, that seems to indicate your paper has been accepted:

[ https://cmsworkshops.com/ICASSP2026/author\_invitation\_request.php ](https://cmsworkshops.com/ICASSP2026/author_invitation_request.php)

The email says: “On behalf of IEEE ICASSP 2026, I invite you to join us for the upcoming conference.

We are pleased to inform you that your submission has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) in Barcelona, Spain, during 3–8 May 2026. ICASSP is the world’s largest and most comprehensive technical conference focused on signal processing and its applications. It offers a comprehensive technical program presenting all the latest development in research and technology in the industry that attracts thousands of professionals annually.”

Hopefully this helps others who are anxiously waiting. Good luck everyone

\--------

Update: It was a bug that got fixed within a few hours. It looks like no one can access it right now.

“Error: No match for paper number and password. 0x4C”.

\--------

Update: Just got the official email! 🥰 ID 9000-10000

Some folks haven’t gotten the email yet, but they can already find their papers on the accepted list here:

[ https://cmsworkshops.com/ICASSP2026/papers/accepted\_papers.php ](https://cmsworkshops.com/ICASSP2026/papers/accepted_papers.php)

you can also check a community-maintained spreadsheet compiled by users on another platform:

[ https://docs.qq.com/sheet/DY3NTYVhwVVVGUUtx?tab=BB08J2 ](https://docs.qq.com/sheet/DY3NTYVhwVVVGUUtx?tab=BB08J2)

The list is still updating, so no worries if yours isn’t there yet just give it a bit more time.

You can check your paper status here:

[https://cmsworkshops.com/ICASSP2026/Papers/FindPaperStatus.asp](https://cmsworkshops.com/ICASSP2026/Papers/FindPaperStatus.asp)",36,105,0.9,1768576715.0,/r/MachineLearning/comments/1qeips6/d_icassp_2026_results/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""It looks like ICASSP 2026 decisions may already be accessible.\n\nIf you can log in to the following link and successfully send an invitation email, that seems to indicate your paper has been accepted:\n\n[ https://cmsworkshops.com/ICASSP2026/author\\_invitation\\_request.php ](https://cmsworkshops.com/ICASSP2026/author_invitation_request.php)\n\nThe email says: “On behalf of IEEE ICASSP 2026, I invite you to join us for the upcoming conference.\n\nWe are pleased to inform you that your submission has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) in Barcelona, Spain, during 3–8 May 2026. ICASSP is the world’s largest and most comprehensive technical conference focused on signal processing and its applications. It offers a comprehensive technical program presenting all the latest development in research and technology in the industry that attracts thousands of professionals annually.”\n\nHopefully this helps others who are anxiously waiting. Good luck everyone\n\n\\--------\n\nUpdate: It was a bug that got fixed within a few hours. It looks like no one can access it right now.\n\n“Error: No match for paper number and password. 0x4C”.\n\n\\--------\n\nUpdate: Just got the official email! 🥰 ID 9000-10000\n\nSome folks haven’t gotten the email yet, but they can already find their papers on the accepted list here:\n\n[ https://cmsworkshops.com/ICASSP2026/papers/accepted\\_papers.php ](https://cmsworkshops.com/ICASSP2026/papers/accepted_papers.php)\n\nyou can also check a community-maintained spreadsheet compiled by users on another platform:\n\n[ https://docs.qq.com/sheet/DY3NTYVhwVVVGUUtx?tab=BB08J2 ](https://docs.qq.com/sheet/DY3NTYVhwVVVGUUtx?tab=BB08J2)\n\nThe list is still updating, so no worries if yours isn’t there yet just give it a bit more time.\n\nYou can check your paper status here:\n\n[https://cmsworkshops.com/ICASSP2026/Papers/FindPaperStatus.asp](https://cmsworkshops.com/ICASSP2026/Papers/FindPaperStatus.asp)"", ""author_fullname"": ""t2_1z6q1ti6mt"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] ICASSP 2026 Results"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qeips6"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.9, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 36, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Discussion"", ""can_mod_post"": false, ""score"": 36, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": 1768675461.0, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768576715.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;It looks like ICASSP 2026 decisions may already be accessible.&lt;/p&gt;\n\n&lt;p&gt;If you can log in to the following link and successfully send an invitation email, that seems to indicate your paper has been accepted:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\""https://cmsworkshops.com/ICASSP2026/author_invitation_request.php\""&gt; https://cmsworkshops.com/ICASSP2026/author_invitation_request.php &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The email says: “On behalf of IEEE ICASSP 2026, I invite you to join us for the upcoming conference.&lt;/p&gt;\n\n&lt;p&gt;We are pleased to inform you that your submission has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) in Barcelona, Spain, during 3–8 May 2026. ICASSP is the world’s largest and most comprehensive technical conference focused on signal processing and its applications. It offers a comprehensive technical program presenting all the latest development in research and technology in the industry that attracts thousands of professionals annually.”&lt;/p&gt;\n\n&lt;p&gt;Hopefully this helps others who are anxiously waiting. Good luck everyone&lt;/p&gt;\n\n&lt;p&gt;--------&lt;/p&gt;\n\n&lt;p&gt;Update: It was a bug that got fixed within a few hours. It looks like no one can access it right now.&lt;/p&gt;\n\n&lt;p&gt;“Error: No match for paper number and password. 0x4C”.&lt;/p&gt;\n\n&lt;p&gt;--------&lt;/p&gt;\n\n&lt;p&gt;Update: Just got the official email! 🥰 ID 9000-10000&lt;/p&gt;\n\n&lt;p&gt;Some folks haven’t gotten the email yet, but they can already find their papers on the accepted list here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\""https://cmsworkshops.com/ICASSP2026/papers/accepted_papers.php\""&gt; https://cmsworkshops.com/ICASSP2026/papers/accepted_papers.php &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;you can also check a community-maintained spreadsheet compiled by users on another platform:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\""https://docs.qq.com/sheet/DY3NTYVhwVVVGUUtx?tab=BB08J2\""&gt; https://docs.qq.com/sheet/DY3NTYVhwVVVGUUtx?tab=BB08J2 &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The list is still updating, so no worries if yours isn’t there yet just give it a bit more time.&lt;/p&gt;\n\n&lt;p&gt;You can check your paper status here:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\""https://cmsworkshops.com/ICASSP2026/Papers/FindPaperStatus.asp\""&gt;https://cmsworkshops.com/ICASSP2026/Papers/FindPaperStatus.asp&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""15995904-19d4-11f0-b8c9-0eed6ea89bc1"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#26c4d9"", ""id"": ""1qeips6"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""Financial-Panda6581"", ""discussion_type"": null, ""num_comments"": 105, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qeips6/d_icassp_2026_results/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qeips6/d_icassp_2026_results/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768576715.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qe1u5f,MachineLearning,sailor-goon-is-here,[D] Scale AI ML Research Engineer Interviews,"Hi, I'm looking for help into preparing for the upcoming coding interviews for an ML research engineer position I applied to at Scale. These are for the onsite.

The first coding question relates parsing data, data transformations, getting statistics about the data. The second (ML) coding involves ML concepts, LLMs, and debugging.

I found the description of the ML part to be a bit vague. For those that have done this type of interview, what did you do to prepare? So far on my list, I have reviewing hyperparameters of LLMs, PyTorch debugging, transformer debugging, and data pipeline pre-processing, ingestion, etc. Will I need to implement NLP or CV algorithms from scratch?

Any insight to this would be really helpful.",38,12,0.85,1768525596.0,/r/MachineLearning/comments/1qe1u5f/d_scale_ai_ml_research_engineer_interviews/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""Hi, I'm looking for help into preparing for the upcoming coding interviews for an ML research engineer position I applied to at Scale. These are for the onsite.\n\nThe first coding question relates parsing data, data transformations, getting statistics about the data. The second (ML) coding involves ML concepts, LLMs, and debugging.\n\nI found the description of the ML part to be a bit vague. For those that have done this type of interview, what did you do to prepare? So far on my list, I have reviewing hyperparameters of LLMs, PyTorch debugging, transformer debugging, and data pipeline pre-processing, ingestion, etc. Will I need to implement NLP or CV algorithms from scratch?\n\nAny insight to this would be really helpful."", ""author_fullname"": ""t2_60jx0g1n"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] Scale AI ML Research Engineer Interviews"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qe1u5f"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.85, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 38, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Discussion"", ""can_mod_post"": false, ""score"": 38, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768525596.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;Hi, I&amp;#39;m looking for help into preparing for the upcoming coding interviews for an ML research engineer position I applied to at Scale. These are for the onsite.&lt;/p&gt;\n\n&lt;p&gt;The first coding question relates parsing data, data transformations, getting statistics about the data. The second (ML) coding involves ML concepts, LLMs, and debugging.&lt;/p&gt;\n\n&lt;p&gt;I found the description of the ML part to be a bit vague. For those that have done this type of interview, what did you do to prepare? So far on my list, I have reviewing hyperparameters of LLMs, PyTorch debugging, transformer debugging, and data pipeline pre-processing, ingestion, etc. Will I need to implement NLP or CV algorithms from scratch?&lt;/p&gt;\n\n&lt;p&gt;Any insight to this would be really helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""15995904-19d4-11f0-b8c9-0eed6ea89bc1"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#26c4d9"", ""id"": ""1qe1u5f"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""sailor-goon-is-here"", ""discussion_type"": null, ""num_comments"": 12, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qe1u5f/d_scale_ai_ml_research_engineer_interviews/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qe1u5f/d_scale_ai_ml_research_engineer_interviews/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768525596.0, ""num_crossposts"": 1, ""media"": null, ""is_video"": false}"
1qc6ybk,MachineLearning,kwk236,"[P] Awesome Physical AI – A curated list of academic papers and resources on Physical AI — focusing on VLA models, world models, embodied intelligence, and robotic foundation models.","I've been compiling papers on Physical AI — the intersection of foundation models and robotics. This covers Vision-Language-Action (VLA) models like RT-2 and π₀, world models (DreamerV3, Genie 2, JEPA), diffusion policies, real-world deployment and latency problems, cross-embodiment transfer, scaling laws, and safety/alignment for robots.

The field has exploded in the past 18 months. We went from ""lets try llms on robotics"" to having so many dimensions to optimize for. so felt right to maintain a running list of resources.

Organized by: foundations → architectures → action representations → world models → learning paradigms → deployment → applications.

Contributions welcome — especially corrections and missing papers.  
[https://github.com/keon/awesome-physical-ai](https://github.com/keon/awesome-physical-ai)",36,5,0.9,1768346660.0,/r/MachineLearning/comments/1qc6ybk/p_awesome_physical_ai_a_curated_list_of_academic/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""I've been compiling papers on Physical AI — the intersection of foundation models and robotics. This covers Vision-Language-Action (VLA) models like RT-2 and π₀, world models (DreamerV3, Genie 2, JEPA), diffusion policies, real-world deployment and latency problems, cross-embodiment transfer, scaling laws, and safety/alignment for robots.\n\nThe field has exploded in the past 18 months. We went from \""lets try llms on robotics\"" to having so many dimensions to optimize for. so felt right to maintain a running list of resources.\n\nOrganized by: foundations → architectures → action representations → world models → learning paradigms → deployment → applications.\n\nContributions welcome — especially corrections and missing papers.  \n[https://github.com/keon/awesome-physical-ai](https://github.com/keon/awesome-physical-ai)"", ""author_fullname"": ""t2_okfve"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[P] Awesome Physical AI – A curated list of academic papers and resources on Physical AI — focusing on VLA models, world models, embodied intelligence, and robotic foundation models."", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qc6ybk"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.9, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 36, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Project"", ""can_mod_post"": false, ""score"": 36, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""post_hint"": ""self"", ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768346660.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;I&amp;#39;ve been compiling papers on Physical AI — the intersection of foundation models and robotics. This covers Vision-Language-Action (VLA) models like RT-2 and π₀, world models (DreamerV3, Genie 2, JEPA), diffusion policies, real-world deployment and latency problems, cross-embodiment transfer, scaling laws, and safety/alignment for robots.&lt;/p&gt;\n\n&lt;p&gt;The field has exploded in the past 18 months. We went from &amp;quot;lets try llms on robotics&amp;quot; to having so many dimensions to optimize for. so felt right to maintain a running list of resources.&lt;/p&gt;\n\n&lt;p&gt;Organized by: foundations → architectures → action representations → world models → learning paradigms → deployment → applications.&lt;/p&gt;\n\n&lt;p&gt;Contributions welcome — especially corrections and missing papers.&lt;br/&gt;\n&lt;a href=\""https://github.com/keon/awesome-physical-ai\""&gt;https://github.com/keon/awesome-physical-ai&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""preview"": {""images"": [{""source"": {""url"": ""https://external-preview.redd.it/eX7iDHJZhlVGHHr-R7rWIk2OkCjYdmjUk3WCET5eS5s.png?auto=webp&amp;s=9f51d324be2eb91c04641cc0f6c9d3a80d298751"", ""width"": 1200, ""height"": 600}, ""resolutions"": [{""url"": ""https://external-preview.redd.it/eX7iDHJZhlVGHHr-R7rWIk2OkCjYdmjUk3WCET5eS5s.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d89d7433f1d3010448c4d1ad0f867974f076ee2e"", ""width"": 108, ""height"": 54}, {""url"": ""https://external-preview.redd.it/eX7iDHJZhlVGHHr-R7rWIk2OkCjYdmjUk3WCET5eS5s.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7ff01cbb655ed2e204341f9e0c136f7231cd4a13"", ""width"": 216, ""height"": 108}, {""url"": ""https://external-preview.redd.it/eX7iDHJZhlVGHHr-R7rWIk2OkCjYdmjUk3WCET5eS5s.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=844557771a6c332f4a71fd5ac997ac2578ac839a"", ""width"": 320, ""height"": 160}, {""url"": ""https://external-preview.redd.it/eX7iDHJZhlVGHHr-R7rWIk2OkCjYdmjUk3WCET5eS5s.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d40d657d38b80af8efbde2275ea1d164d983d651"", ""width"": 640, ""height"": 320}, {""url"": ""https://external-preview.redd.it/eX7iDHJZhlVGHHr-R7rWIk2OkCjYdmjUk3WCET5eS5s.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ffb3bb6eb88a50f0e48fbcc1fa0994c7e8aa2029"", ""width"": 960, ""height"": 480}, {""url"": ""https://external-preview.redd.it/eX7iDHJZhlVGHHr-R7rWIk2OkCjYdmjUk3WCET5eS5s.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0ec326eed0ae648f7c351715d05fb66ec641dda2"", ""width"": 1080, ""height"": 540}], ""variants"": {}, ""id"": ""eX7iDHJZhlVGHHr-R7rWIk2OkCjYdmjUk3WCET5eS5s""}], ""enabled"": false}, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""c6dea51c-19d3-11f0-81a2-deb9d8e21ccb"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#7d659a"", ""id"": ""1qc6ybk"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""kwk236"", ""discussion_type"": null, ""num_comments"": 5, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qc6ybk/p_awesome_physical_ai_a_curated_list_of_academic/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qc6ybk/p_awesome_physical_ai_a_curated_list_of_academic/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768346660.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qffcgi,MachineLearning,ChavXO,[D] LLMs as a semantic regularizer for feature synthesis (small decision-tree experiment),"I’ve been experimenting with using LLMs not to generate features, but instead to filter them during enumerative feature synthesis.

The approach was inspired by this paper: https://arxiv.org/pdf/2403.03997v1

I had already been playing with enumerative bottom up synthesis but noticed it usually gave me unintelligible features (even with regularization).

I looked into how other symbolic approaches deal with this problem and saw that they tried to model the semantics of the domain somehow - including dimensions, refinement types etc. But those approaches weren't appealing to me because I was trying to come up with something that worked in general.

So I tried using an LLM to score candidate expressions by how meaningful they are. The idea was that the semantic meaning of the column names, the dimensions, and the salience of the operations could be embedded in the LLM.

My approach was:
* Enumerate simple arithmetic features (treat feature eng as program synthesis)
* Use an LLM as a semantic filter (“does this look like a meaningful quantity?”)
* Train a decision tree (with oblique splits) considering only the filtered candidates as potential splits.

The result was that the tree was noticeably more readable, accuracy was similar / slightly better in my small test.


I wrote it up here: https://mchav.github.io/learning-better-decision-tree-splits/
Runnable code is [here](https://github.com/mchav/dataframe/blob/main/app%2FREADME.md)

If you’ve tried constraining feature synthesis before: what filters worked best in practice? Are the any measures of semantic viability out there?",36,16,0.92,1768661995.0,/r/MachineLearning/comments/1qffcgi/d_llms_as_a_semantic_regularizer_for_feature/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""I’ve been experimenting with using LLMs not to generate features, but instead to filter them during enumerative feature synthesis.\n\nThe approach was inspired by this paper: https://arxiv.org/pdf/2403.03997v1\n\nI had already been playing with enumerative bottom up synthesis but noticed it usually gave me unintelligible features (even with regularization).\n\nI looked into how other symbolic approaches deal with this problem and saw that they tried to model the semantics of the domain somehow - including dimensions, refinement types etc. But those approaches weren't appealing to me because I was trying to come up with something that worked in general.\n\nSo I tried using an LLM to score candidate expressions by how meaningful they are. The idea was that the semantic meaning of the column names, the dimensions, and the salience of the operations could be embedded in the LLM.\n\nMy approach was:\n* Enumerate simple arithmetic features (treat feature eng as program synthesis)\n* Use an LLM as a semantic filter (“does this look like a meaningful quantity?”)\n* Train a decision tree (with oblique splits) considering only the filtered candidates as potential splits.\n\nThe result was that the tree was noticeably more readable, accuracy was similar / slightly better in my small test.\n\n\nI wrote it up here: https://mchav.github.io/learning-better-decision-tree-splits/\nRunnable code is [here](https://github.com/mchav/dataframe/blob/main/app%2FREADME.md)\n\nIf you’ve tried constraining feature synthesis before: what filters worked best in practice? Are the any measures of semantic viability out there?"", ""author_fullname"": ""t2_sch4w"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] LLMs as a semantic regularizer for feature synthesis (small decision-tree experiment)"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qffcgi"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.92, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 36, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Discussion"", ""can_mod_post"": false, ""score"": 36, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": 1768722334.0, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768661995.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;I’ve been experimenting with using LLMs not to generate features, but instead to filter them during enumerative feature synthesis.&lt;/p&gt;\n\n&lt;p&gt;The approach was inspired by this paper: &lt;a href=\""https://arxiv.org/pdf/2403.03997v1\""&gt;https://arxiv.org/pdf/2403.03997v1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I had already been playing with enumerative bottom up synthesis but noticed it usually gave me unintelligible features (even with regularization).&lt;/p&gt;\n\n&lt;p&gt;I looked into how other symbolic approaches deal with this problem and saw that they tried to model the semantics of the domain somehow - including dimensions, refinement types etc. But those approaches weren&amp;#39;t appealing to me because I was trying to come up with something that worked in general.&lt;/p&gt;\n\n&lt;p&gt;So I tried using an LLM to score candidate expressions by how meaningful they are. The idea was that the semantic meaning of the column names, the dimensions, and the salience of the operations could be embedded in the LLM.&lt;/p&gt;\n\n&lt;p&gt;My approach was:\n* Enumerate simple arithmetic features (treat feature eng as program synthesis)\n* Use an LLM as a semantic filter (“does this look like a meaningful quantity?”)\n* Train a decision tree (with oblique splits) considering only the filtered candidates as potential splits.&lt;/p&gt;\n\n&lt;p&gt;The result was that the tree was noticeably more readable, accuracy was similar / slightly better in my small test.&lt;/p&gt;\n\n&lt;p&gt;I wrote it up here: &lt;a href=\""https://mchav.github.io/learning-better-decision-tree-splits/\""&gt;https://mchav.github.io/learning-better-decision-tree-splits/&lt;/a&gt;\nRunnable code is &lt;a href=\""https://github.com/mchav/dataframe/blob/main/app%2FREADME.md\""&gt;here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you’ve tried constraining feature synthesis before: what filters worked best in practice? Are the any measures of semantic viability out there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""15995904-19d4-11f0-b8c9-0eed6ea89bc1"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#26c4d9"", ""id"": ""1qffcgi"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""ChavXO"", ""discussion_type"": null, ""num_comments"": 16, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qffcgi/d_llms_as_a_semantic_regularizer_for_feature/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qffcgi/d_llms_as_a_semantic_regularizer_for_feature/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768661995.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qgac9b,MachineLearning,montebicyclelo,[P] SmallPebble: A minimalist deep learning library written from scratch in NumPy,,33,2,0.92,1768747440.0,/r/MachineLearning/comments/1qgac9b/p_smallpebble_a_minimalist_deep_learning_library/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": """", ""author_fullname"": ""t2_45cd4qfn"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[P] SmallPebble: A minimalist deep learning library written from scratch in NumPy"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": 70, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qgac9b"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.92, ""author_flair_background_color"": null, ""ups"": 33, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": 140, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Project"", ""can_mod_post"": false, ""score"": 33, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""https://external-preview.redd.it/t1PhrCms2xJPum85RtSZ2t7U4Oo1dh-XaDIBq-VhYP4.png?width=140&amp;height=70&amp;auto=webp&amp;s=839d9a871390ccd32b054356436f047905b3caee"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""post_hint"": ""link"", ""content_categories"": null, ""is_self"": false, ""subreddit_type"": ""public"", ""created"": 1768747440.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""github.com"", ""allow_live_comments"": false, ""selftext_html"": null, ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""url_overridden_by_dest"": ""https://github.com/sradc/SmallPebble"", ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""preview"": {""images"": [{""source"": {""url"": ""https://external-preview.redd.it/t1PhrCms2xJPum85RtSZ2t7U4Oo1dh-XaDIBq-VhYP4.png?auto=webp&amp;s=bfb1099c8ac3fdd9920d4d75d1271f653e9b202f"", ""width"": 1200, ""height"": 600}, ""resolutions"": [{""url"": ""https://external-preview.redd.it/t1PhrCms2xJPum85RtSZ2t7U4Oo1dh-XaDIBq-VhYP4.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=26519aa0cce8c6ea03cdaaa68f22ee00101349e3"", ""width"": 108, ""height"": 54}, {""url"": ""https://external-preview.redd.it/t1PhrCms2xJPum85RtSZ2t7U4Oo1dh-XaDIBq-VhYP4.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=838eec0d60fb545d20a595d350b80873181c8e50"", ""width"": 216, ""height"": 108}, {""url"": ""https://external-preview.redd.it/t1PhrCms2xJPum85RtSZ2t7U4Oo1dh-XaDIBq-VhYP4.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=38b9e0c248366d6ef544f202bd8a34d5f09e90c9"", ""width"": 320, ""height"": 160}, {""url"": ""https://external-preview.redd.it/t1PhrCms2xJPum85RtSZ2t7U4Oo1dh-XaDIBq-VhYP4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=db885b8775ce856afeb4d53b526d6386df1e6db5"", ""width"": 640, ""height"": 320}, {""url"": ""https://external-preview.redd.it/t1PhrCms2xJPum85RtSZ2t7U4Oo1dh-XaDIBq-VhYP4.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ff55fa785d9e4799446754e21a13d7439a7df8fc"", ""width"": 960, ""height"": 480}, {""url"": ""https://external-preview.redd.it/t1PhrCms2xJPum85RtSZ2t7U4Oo1dh-XaDIBq-VhYP4.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2f12e10265f80d6b7a90c092695c8127a262d383"", ""width"": 1080, ""height"": 540}], ""variants"": {}, ""id"": ""t1PhrCms2xJPum85RtSZ2t7U4Oo1dh-XaDIBq-VhYP4""}], ""enabled"": false}, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""c6dea51c-19d3-11f0-81a2-deb9d8e21ccb"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""mod_note"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""num_reports"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#7d659a"", ""id"": ""1qgac9b"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""montebicyclelo"", ""discussion_type"": null, ""num_comments"": 2, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qgac9b/p_smallpebble_a_minimalist_deep_learning_library/"", ""stickied"": false, ""url"": ""https://github.com/sradc/SmallPebble"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768747440.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qcyd7z,MachineLearning,LaniakeaResident,"Spine surgery has massive decision variability. Retrospective ML won’t fix it. Curious if a workflow-native, outcome-driven approach could. [D]","Hi everyone I’m a fellowship-trained neurosurgeon / spine surgeon. I’ve been discussing a persistent problem in our field with other surgeons for a while, and I wanted to run it by people who think about ML systems, not just model performance.

I’m trying to pressure-test whether a particular approach is even technically sound, where it would break, and what I’m likely underestimating. Id love to find an interested person to have a discussion with to get a 10000 feet level understanding of the scope of what I am trying to accomplish.

**The clinical problem:**  
For the same spine pathology and very similar patient presentations, you can see multiple reputable surgeons and get very different surgical recommendations. anything from continued conservative management to decompression, short fusion, or long multilevel constructs. Costs and outcomes vary widely.

This isn’t because surgeons are careless. It’s because spine surgery operates with:

* Limited prospective evidence
* Inconsistent documentation
* Weak outcome feedback loops
* Retrospective datasets that are biased, incomplete, and poorly labeled

EMRs are essentially digital paper charts. PACS is built for viewing images, not capturing *decision intent*. Surgical reasoning is visual, spatial, and 3D, yet we reduce it to free-text notes after the fact. From a data perspective, the learning signal is pretty broken.

**Why I’m skeptical that training on existing data works:**

* “Labels” are often inferred indirectly (billing codes, op notes)
* Surgeon decision policies are non-stationary
* Available datasets are institution-specific and access-restricted
* Selection bias is extreme (who gets surgery vs who doesn’t is itself a learned policy)
* Outcomes are delayed, noisy, and confounded

Even with access, I’m not convinced retrospective supervision converges to something clinically useful.

**The idea I’m exploring:**  
Instead of trying to clean bad data later, what if the workflow itself generated structured, high-fidelity labels as a byproduct of doing the work, or at least the majority of it?

Concretely, I’m imagining an EMR-adjacent, spine-specific surgical planning and case monitoring environment that surgeons would actually want to use. Not another PACS viewer, but a system that allows:

* 3D reconstruction from pre-op imaging
* Automated calculation of alignment parameters
* Explicit marking of anatomic features tied to symptoms
* Surgical plan modeling (levels, implants, trajectories, correction goals)
* Structured logging of surgical cases (to derive patterns and analyze for trends)
* Enable productivity (generate note, auto populate plans ect.)
* Enable standardized automated patient outcomes data collection.

The key point isn’t the UI, but UI is also an area that currently suffers. It’s that surgeons would be forced (in a useful way) to externalize decision intent in a structured format because it directly helps them plan cases and generate documentation. Labeling wouldn’t feel like labeling it would almost just be how you work. The data used for learning would explicitly include post-operative outcomes. PROMs collected at standardized intervals, complications (SSI, reoperation), operative time, etc, with automated follow-up built into the system.

The goal would not be to replicate surgeon decisions, but to learn decision patterns that are associated with better outcomes. Surgeons could specify what they want to optimize for a given patient (eg pain relief vs complication risk vs durability), and the system would generate predictions conditioned on those objectives.

Over time, this would generate:

* Surgeon-specific decision + outcome datasets
* Aggregate cross-surgeon data
* Explicit representations of surgical choices, not just endpoints

Learning systems could then train on:

* Individual surgeon decision–outcome mappings
* Population-level patterns
* Areas of divergence where similar cases lead to different choices and outcomes

**Where I’m unsure, and why I’m posting here:**

From an ML perspective, I’m trying to understand:

* Given delayed, noisy outcomes, is this best framed as supervised prediction or closer to learning decision policies under uncertainty?
* How feasible is it to attribute outcome differences to surgical decisions rather than execution, environment, or case selection?
* Does it make sense to learn surgeon-specific decision–outcome mappings before attempting cross-surgeon generalization?
* How would you prevent optimizing for measurable metrics (PROMs, SSI, etc) at the expense of unmeasured but important patient outcomes?
* Which outcome signals are realistically usable for learning, and which are too delayed or confounded?
* What failure modes jump out immediately?

I’m also trying to get a realistic sense of:

* The data engineering complexity this implies
* Rough scale of compute once models actually exist
* The kind of team required to even attempt this (beyond just training models)

I know there are a lot of missing details. If anyone here has worked on complex ML systems tightly coupled to real-world workflows (medical imaging, decision support, etc) and finds this interesting, I’d love to continue the discussion privately or over Zoom. Maybe we can collaborate on some level!

Appreciate any critique especially the uncomfortable kind!!",32,24,0.83,1768422339.0,/r/MachineLearning/comments/1qcyd7z/spine_surgery_has_massive_decision_variability/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""Hi everyone I’m a fellowship-trained neurosurgeon / spine surgeon. I’ve been discussing a persistent problem in our field with other surgeons for a while, and I wanted to run it by people who think about ML systems, not just model performance.\n\nI’m trying to pressure-test whether a particular approach is even technically sound, where it would break, and what I’m likely underestimating. Id love to find an interested person to have a discussion with to get a 10000 feet level understanding of the scope of what I am trying to accomplish.\n\n**The clinical problem:**  \nFor the same spine pathology and very similar patient presentations, you can see multiple reputable surgeons and get very different surgical recommendations. anything from continued conservative management to decompression, short fusion, or long multilevel constructs. Costs and outcomes vary widely.\n\nThis isn’t because surgeons are careless. It’s because spine surgery operates with:\n\n* Limited prospective evidence\n* Inconsistent documentation\n* Weak outcome feedback loops\n* Retrospective datasets that are biased, incomplete, and poorly labeled\n\nEMRs are essentially digital paper charts. PACS is built for viewing images, not capturing *decision intent*. Surgical reasoning is visual, spatial, and 3D, yet we reduce it to free-text notes after the fact. From a data perspective, the learning signal is pretty broken.\n\n**Why I’m skeptical that training on existing data works:**\n\n* “Labels” are often inferred indirectly (billing codes, op notes)\n* Surgeon decision policies are non-stationary\n* Available datasets are institution-specific and access-restricted\n* Selection bias is extreme (who gets surgery vs who doesn’t is itself a learned policy)\n* Outcomes are delayed, noisy, and confounded\n\nEven with access, I’m not convinced retrospective supervision converges to something clinically useful.\n\n**The idea I’m exploring:**  \nInstead of trying to clean bad data later, what if the workflow itself generated structured, high-fidelity labels as a byproduct of doing the work, or at least the majority of it?\n\nConcretely, I’m imagining an EMR-adjacent, spine-specific surgical planning and case monitoring environment that surgeons would actually want to use. Not another PACS viewer, but a system that allows:\n\n* 3D reconstruction from pre-op imaging\n* Automated calculation of alignment parameters\n* Explicit marking of anatomic features tied to symptoms\n* Surgical plan modeling (levels, implants, trajectories, correction goals)\n* Structured logging of surgical cases (to derive patterns and analyze for trends)\n* Enable productivity (generate note, auto populate plans ect.)\n* Enable standardized automated patient outcomes data collection.\n\nThe key point isn’t the UI, but UI is also an area that currently suffers. It’s that surgeons would be forced (in a useful way) to externalize decision intent in a structured format because it directly helps them plan cases and generate documentation. Labeling wouldn’t feel like labeling it would almost just be how you work. The data used for learning would explicitly include post-operative outcomes. PROMs collected at standardized intervals, complications (SSI, reoperation), operative time, etc, with automated follow-up built into the system.\n\nThe goal would not be to replicate surgeon decisions, but to learn decision patterns that are associated with better outcomes. Surgeons could specify what they want to optimize for a given patient (eg pain relief vs complication risk vs durability), and the system would generate predictions conditioned on those objectives.\n\nOver time, this would generate:\n\n* Surgeon-specific decision + outcome datasets\n* Aggregate cross-surgeon data\n* Explicit representations of surgical choices, not just endpoints\n\nLearning systems could then train on:\n\n* Individual surgeon decision–outcome mappings\n* Population-level patterns\n* Areas of divergence where similar cases lead to different choices and outcomes\n\n**Where I’m unsure, and why I’m posting here:**\n\nFrom an ML perspective, I’m trying to understand:\n\n* Given delayed, noisy outcomes, is this best framed as supervised prediction or closer to learning decision policies under uncertainty?\n* How feasible is it to attribute outcome differences to surgical decisions rather than execution, environment, or case selection?\n* Does it make sense to learn surgeon-specific decision–outcome mappings before attempting cross-surgeon generalization?\n* How would you prevent optimizing for measurable metrics (PROMs, SSI, etc) at the expense of unmeasured but important patient outcomes?\n* Which outcome signals are realistically usable for learning, and which are too delayed or confounded?\n* What failure modes jump out immediately?\n\nI’m also trying to get a realistic sense of:\n\n* The data engineering complexity this implies\n* Rough scale of compute once models actually exist\n* The kind of team required to even attempt this (beyond just training models)\n\nI know there are a lot of missing details. If anyone here has worked on complex ML systems tightly coupled to real-world workflows (medical imaging, decision support, etc) and finds this interesting, I’d love to continue the discussion privately or over Zoom. Maybe we can collaborate on some level!\n\nAppreciate any critique especially the uncomfortable kind!!"", ""author_fullname"": ""t2_ljl8x"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""Spine surgery has massive decision variability. Retrospective ML won’t fix it. Curious if a workflow-native, outcome-driven approach could. [D]"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qcyd7z"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.83, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 32, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Discussion"", ""can_mod_post"": false, ""score"": 32, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768422339.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;Hi everyone I’m a fellowship-trained neurosurgeon / spine surgeon. I’ve been discussing a persistent problem in our field with other surgeons for a while, and I wanted to run it by people who think about ML systems, not just model performance.&lt;/p&gt;\n\n&lt;p&gt;I’m trying to pressure-test whether a particular approach is even technically sound, where it would break, and what I’m likely underestimating. Id love to find an interested person to have a discussion with to get a 10000 feet level understanding of the scope of what I am trying to accomplish.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The clinical problem:&lt;/strong&gt;&lt;br/&gt;\nFor the same spine pathology and very similar patient presentations, you can see multiple reputable surgeons and get very different surgical recommendations. anything from continued conservative management to decompression, short fusion, or long multilevel constructs. Costs and outcomes vary widely.&lt;/p&gt;\n\n&lt;p&gt;This isn’t because surgeons are careless. It’s because spine surgery operates with:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Limited prospective evidence&lt;/li&gt;\n&lt;li&gt;Inconsistent documentation&lt;/li&gt;\n&lt;li&gt;Weak outcome feedback loops&lt;/li&gt;\n&lt;li&gt;Retrospective datasets that are biased, incomplete, and poorly labeled&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;EMRs are essentially digital paper charts. PACS is built for viewing images, not capturing &lt;em&gt;decision intent&lt;/em&gt;. Surgical reasoning is visual, spatial, and 3D, yet we reduce it to free-text notes after the fact. From a data perspective, the learning signal is pretty broken.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why I’m skeptical that training on existing data works:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;“Labels” are often inferred indirectly (billing codes, op notes)&lt;/li&gt;\n&lt;li&gt;Surgeon decision policies are non-stationary&lt;/li&gt;\n&lt;li&gt;Available datasets are institution-specific and access-restricted&lt;/li&gt;\n&lt;li&gt;Selection bias is extreme (who gets surgery vs who doesn’t is itself a learned policy)&lt;/li&gt;\n&lt;li&gt;Outcomes are delayed, noisy, and confounded&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Even with access, I’m not convinced retrospective supervision converges to something clinically useful.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The idea I’m exploring:&lt;/strong&gt;&lt;br/&gt;\nInstead of trying to clean bad data later, what if the workflow itself generated structured, high-fidelity labels as a byproduct of doing the work, or at least the majority of it?&lt;/p&gt;\n\n&lt;p&gt;Concretely, I’m imagining an EMR-adjacent, spine-specific surgical planning and case monitoring environment that surgeons would actually want to use. Not another PACS viewer, but a system that allows:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;3D reconstruction from pre-op imaging&lt;/li&gt;\n&lt;li&gt;Automated calculation of alignment parameters&lt;/li&gt;\n&lt;li&gt;Explicit marking of anatomic features tied to symptoms&lt;/li&gt;\n&lt;li&gt;Surgical plan modeling (levels, implants, trajectories, correction goals)&lt;/li&gt;\n&lt;li&gt;Structured logging of surgical cases (to derive patterns and analyze for trends)&lt;/li&gt;\n&lt;li&gt;Enable productivity (generate note, auto populate plans ect.)&lt;/li&gt;\n&lt;li&gt;Enable standardized automated patient outcomes data collection.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The key point isn’t the UI, but UI is also an area that currently suffers. It’s that surgeons would be forced (in a useful way) to externalize decision intent in a structured format because it directly helps them plan cases and generate documentation. Labeling wouldn’t feel like labeling it would almost just be how you work. The data used for learning would explicitly include post-operative outcomes. PROMs collected at standardized intervals, complications (SSI, reoperation), operative time, etc, with automated follow-up built into the system.&lt;/p&gt;\n\n&lt;p&gt;The goal would not be to replicate surgeon decisions, but to learn decision patterns that are associated with better outcomes. Surgeons could specify what they want to optimize for a given patient (eg pain relief vs complication risk vs durability), and the system would generate predictions conditioned on those objectives.&lt;/p&gt;\n\n&lt;p&gt;Over time, this would generate:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Surgeon-specific decision + outcome datasets&lt;/li&gt;\n&lt;li&gt;Aggregate cross-surgeon data&lt;/li&gt;\n&lt;li&gt;Explicit representations of surgical choices, not just endpoints&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Learning systems could then train on:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Individual surgeon decision–outcome mappings&lt;/li&gt;\n&lt;li&gt;Population-level patterns&lt;/li&gt;\n&lt;li&gt;Areas of divergence where similar cases lead to different choices and outcomes&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Where I’m unsure, and why I’m posting here:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;From an ML perspective, I’m trying to understand:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Given delayed, noisy outcomes, is this best framed as supervised prediction or closer to learning decision policies under uncertainty?&lt;/li&gt;\n&lt;li&gt;How feasible is it to attribute outcome differences to surgical decisions rather than execution, environment, or case selection?&lt;/li&gt;\n&lt;li&gt;Does it make sense to learn surgeon-specific decision–outcome mappings before attempting cross-surgeon generalization?&lt;/li&gt;\n&lt;li&gt;How would you prevent optimizing for measurable metrics (PROMs, SSI, etc) at the expense of unmeasured but important patient outcomes?&lt;/li&gt;\n&lt;li&gt;Which outcome signals are realistically usable for learning, and which are too delayed or confounded?&lt;/li&gt;\n&lt;li&gt;What failure modes jump out immediately?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I’m also trying to get a realistic sense of:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The data engineering complexity this implies&lt;/li&gt;\n&lt;li&gt;Rough scale of compute once models actually exist&lt;/li&gt;\n&lt;li&gt;The kind of team required to even attempt this (beyond just training models)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I know there are a lot of missing details. If anyone here has worked on complex ML systems tightly coupled to real-world workflows (medical imaging, decision support, etc) and finds this interesting, I’d love to continue the discussion privately or over Zoom. Maybe we can collaborate on some level!&lt;/p&gt;\n\n&lt;p&gt;Appreciate any critique especially the uncomfortable kind!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""15995904-19d4-11f0-b8c9-0eed6ea89bc1"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#26c4d9"", ""id"": ""1qcyd7z"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""LaniakeaResident"", ""discussion_type"": null, ""num_comments"": 24, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qcyd7z/spine_surgery_has_massive_decision_variability/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qcyd7z/spine_surgery_has_massive_decision_variability/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768422339.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qdsd84,MachineLearning,dinkinflika0,[P] Adaptive load balancing in Go for LLM traffic - harder than expected,"I am an open source contributor, working on load balancing for Bifrost (LLM gateway) and ran into some interesting challenges with Go implementation.

Standard weighted round-robin works fine for static loads, but LLM providers behave weirdly. OpenAI might be fast at 9am, slow at 2pm. Azure rate limits kick in unexpectedly. One region degrades while others stay healthy.

Built adaptive routing that adjusts weights based on live metrics - latency, error rates, throughput. Used EWMAs (exponentially weighted moving averages) to smooth out spikes without overreacting to noise.

The Go part that was tricky: tracking per-provider metrics without locks becoming a bottleneck at high RPS. Ended up using atomic operations for counters and a separate goroutine that periodically reads metrics and recalculates weights. Keeps the hot path lock-free.

Also had to handle provider health scoring. Not just ""up or down"" but scoring based on recent performance. A provider recovering from issues should gradually earn traffic back, not get slammed immediately.

Connection pooling matters more than expected. Go's http.Transport reuses connections well, but tuning MaxIdleConnsPerHost made a noticeable difference under sustained load.

Running this at 5K RPS with sub-microsecond overhead now. The concurrency primitives in Go made this way easier than Python would've been.

Anyone else built adaptive routing in Go? What patterns worked for you?",23,1,0.93,1768503519.0,/r/MachineLearning/comments/1qdsd84/p_adaptive_load_balancing_in_go_for_llm_traffic/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""I am an open source contributor, working on load balancing for Bifrost (LLM gateway) and ran into some interesting challenges with Go implementation.\n\nStandard weighted round-robin works fine for static loads, but LLM providers behave weirdly. OpenAI might be fast at 9am, slow at 2pm. Azure rate limits kick in unexpectedly. One region degrades while others stay healthy.\n\nBuilt adaptive routing that adjusts weights based on live metrics - latency, error rates, throughput. Used EWMAs (exponentially weighted moving averages) to smooth out spikes without overreacting to noise.\n\nThe Go part that was tricky: tracking per-provider metrics without locks becoming a bottleneck at high RPS. Ended up using atomic operations for counters and a separate goroutine that periodically reads metrics and recalculates weights. Keeps the hot path lock-free.\n\nAlso had to handle provider health scoring. Not just \""up or down\"" but scoring based on recent performance. A provider recovering from issues should gradually earn traffic back, not get slammed immediately.\n\nConnection pooling matters more than expected. Go's http.Transport reuses connections well, but tuning MaxIdleConnsPerHost made a noticeable difference under sustained load.\n\nRunning this at 5K RPS with sub-microsecond overhead now. The concurrency primitives in Go made this way easier than Python would've been.\n\nAnyone else built adaptive routing in Go? What patterns worked for you?"", ""author_fullname"": ""t2_6fxogmyi"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[P] Adaptive load balancing in Go for LLM traffic - harder than expected"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qdsd84"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.93, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 23, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Project"", ""can_mod_post"": false, ""score"": 23, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768503519.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;I am an open source contributor, working on load balancing for Bifrost (LLM gateway) and ran into some interesting challenges with Go implementation.&lt;/p&gt;\n\n&lt;p&gt;Standard weighted round-robin works fine for static loads, but LLM providers behave weirdly. OpenAI might be fast at 9am, slow at 2pm. Azure rate limits kick in unexpectedly. One region degrades while others stay healthy.&lt;/p&gt;\n\n&lt;p&gt;Built adaptive routing that adjusts weights based on live metrics - latency, error rates, throughput. Used EWMAs (exponentially weighted moving averages) to smooth out spikes without overreacting to noise.&lt;/p&gt;\n\n&lt;p&gt;The Go part that was tricky: tracking per-provider metrics without locks becoming a bottleneck at high RPS. Ended up using atomic operations for counters and a separate goroutine that periodically reads metrics and recalculates weights. Keeps the hot path lock-free.&lt;/p&gt;\n\n&lt;p&gt;Also had to handle provider health scoring. Not just &amp;quot;up or down&amp;quot; but scoring based on recent performance. A provider recovering from issues should gradually earn traffic back, not get slammed immediately.&lt;/p&gt;\n\n&lt;p&gt;Connection pooling matters more than expected. Go&amp;#39;s http.Transport reuses connections well, but tuning MaxIdleConnsPerHost made a noticeable difference under sustained load.&lt;/p&gt;\n\n&lt;p&gt;Running this at 5K RPS with sub-microsecond overhead now. The concurrency primitives in Go made this way easier than Python would&amp;#39;ve been.&lt;/p&gt;\n\n&lt;p&gt;Anyone else built adaptive routing in Go? What patterns worked for you?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""c6dea51c-19d3-11f0-81a2-deb9d8e21ccb"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#7d659a"", ""id"": ""1qdsd84"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""dinkinflika0"", ""discussion_type"": null, ""num_comments"": 1, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qdsd84/p_adaptive_load_balancing_in_go_for_llm_traffic/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qdsd84/p_adaptive_load_balancing_in_go_for_llm_traffic/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768503519.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qgwtas,MachineLearning,Winter_Ant_4196,[D] tested file based memory vs embedding search for my chatbot. the difference in retrieval accuracy was bigger than i expected,"been working on a personal assistant that needs to remember user preferences, past conversations, and reference documents. tested two approaches for memory retrieval and wanted to share what i found.   
  
setup: about 5k memory items accumulated over 2 months of usage. mix of conversation history, user preferences, and document excerpts.

approach 1: standard rag with embedding search. used openai embeddings with pgvector. retrieval was fast, maybe 200ms per query. but accuracy was inconsistent. worked great for direct factual queries like ""whats my favorite restaurant"" but struggled with temporal queries like ""what did we discuss about the project last tuesday"" or logical queries like ""which of my preferences conflict with each other""

approach 2: file based memory using memU framework. it organizes memory items into thematic files that the model reads directly. retrieval is slower because the model has to process more tokens but the accuracy on complex queries was noticeably better.

rough numbers from my testing (not rigorous, just my observation):

\- simple factual queries: both approaches similar, maybe 85-90% accuracy

\- temporal queries: embedding search around 40%, file based around 75%

\- multi-hop reasoning: embedding search struggled hard, file based was usable

the tradeoff is inference cost. file based approach uses more tokens because the model reads entire memory files. for my use case thats fine because i care more about accuracy than cost. but if youre running at scale the token usage would add up. also worth noting that memU does support embedding search as a fallback so you can combine both approaches. i mostly used the file reading mode.

main takeaway: embedding search is not always the right answer for memory retrieval. depends a lot on what kinds of queries you need to support.",22,4,0.79,1768804591.0,/r/MachineLearning/comments/1qgwtas/d_tested_file_based_memory_vs_embedding_search/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""been working on a personal assistant that needs to remember user preferences, past conversations, and reference documents. tested two approaches for memory retrieval and wanted to share what i found.   \n  \nsetup: about 5k memory items accumulated over 2 months of usage. mix of conversation history, user preferences, and document excerpts.\n\napproach 1: standard rag with embedding search. used openai embeddings with pgvector. retrieval was fast, maybe 200ms per query. but accuracy was inconsistent. worked great for direct factual queries like \""whats my favorite restaurant\"" but struggled with temporal queries like \""what did we discuss about the project last tuesday\"" or logical queries like \""which of my preferences conflict with each other\""\n\napproach 2: file based memory using memU framework. it organizes memory items into thematic files that the model reads directly. retrieval is slower because the model has to process more tokens but the accuracy on complex queries was noticeably better.\n\nrough numbers from my testing (not rigorous, just my observation):\n\n\\- simple factual queries: both approaches similar, maybe 85-90% accuracy\n\n\\- temporal queries: embedding search around 40%, file based around 75%\n\n\\- multi-hop reasoning: embedding search struggled hard, file based was usable\n\nthe tradeoff is inference cost. file based approach uses more tokens because the model reads entire memory files. for my use case thats fine because i care more about accuracy than cost. but if youre running at scale the token usage would add up. also worth noting that memU does support embedding search as a fallback so you can combine both approaches. i mostly used the file reading mode.\n\nmain takeaway: embedding search is not always the right answer for memory retrieval. depends a lot on what kinds of queries you need to support."", ""author_fullname"": ""t2_1buo9smdzj"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] tested file based memory vs embedding search for my chatbot. the difference in retrieval accuracy was bigger than i expected"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qgwtas"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.79, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 22, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Project"", ""can_mod_post"": false, ""score"": 22, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768804591.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;been working on a personal assistant that needs to remember user preferences, past conversations, and reference documents. tested two approaches for memory retrieval and wanted to share what i found.   &lt;/p&gt;\n\n&lt;p&gt;setup: about 5k memory items accumulated over 2 months of usage. mix of conversation history, user preferences, and document excerpts.&lt;/p&gt;\n\n&lt;p&gt;approach 1: standard rag with embedding search. used openai embeddings with pgvector. retrieval was fast, maybe 200ms per query. but accuracy was inconsistent. worked great for direct factual queries like &amp;quot;whats my favorite restaurant&amp;quot; but struggled with temporal queries like &amp;quot;what did we discuss about the project last tuesday&amp;quot; or logical queries like &amp;quot;which of my preferences conflict with each other&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;approach 2: file based memory using memU framework. it organizes memory items into thematic files that the model reads directly. retrieval is slower because the model has to process more tokens but the accuracy on complex queries was noticeably better.&lt;/p&gt;\n\n&lt;p&gt;rough numbers from my testing (not rigorous, just my observation):&lt;/p&gt;\n\n&lt;p&gt;- simple factual queries: both approaches similar, maybe 85-90% accuracy&lt;/p&gt;\n\n&lt;p&gt;- temporal queries: embedding search around 40%, file based around 75%&lt;/p&gt;\n\n&lt;p&gt;- multi-hop reasoning: embedding search struggled hard, file based was usable&lt;/p&gt;\n\n&lt;p&gt;the tradeoff is inference cost. file based approach uses more tokens because the model reads entire memory files. for my use case thats fine because i care more about accuracy than cost. but if youre running at scale the token usage would add up. also worth noting that memU does support embedding search as a fallback so you can combine both approaches. i mostly used the file reading mode.&lt;/p&gt;\n\n&lt;p&gt;main takeaway: embedding search is not always the right answer for memory retrieval. depends a lot on what kinds of queries you need to support.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""c6dea51c-19d3-11f0-81a2-deb9d8e21ccb"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#7d659a"", ""id"": ""1qgwtas"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""Winter_Ant_4196"", ""discussion_type"": null, ""num_comments"": 4, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qgwtas/d_tested_file_based_memory_vs_embedding_search/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qgwtas/d_tested_file_based_memory_vs_embedding_search/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768804591.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qelny9,MachineLearning,waybarrios,[P] vLLM-MLX: Native Apple Silicon LLM inference - 464 tok/s on M4 Max,"Hey everyone!

I built vLLM-MLX - a framework that uses Apple's MLX for native GPU acceleration.

**What it does:**

\- OpenAI-compatible API (drop-in replacement for your existing code)

\- Multimodal support: Text, Images, Video, Audio - all in one server

\- Continuous batching for concurrent users (3.4x speedup)

\- TTS in 10+ languages (Kokoro, Chatterbox models)

\- MCP tool calling support

**Performance on M4 Max:**

\- Llama-3.2-1B-4bit → 464 tok/s

\- Qwen3-0.6B → 402 tok/s

\- Whisper STT → 197x real-time

Works with standard OpenAI Python SDK - just point it to localhost.

**GitHub:** [https://github.com/waybarrios/vllm-mlx](https://github.com/waybarrios/vllm-mlx)",21,4,0.78,1768583110.0,/r/MachineLearning/comments/1qelny9/p_vllmmlx_native_apple_silicon_llm_inference_464/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""Hey everyone!\n\nI built vLLM-MLX - a framework that uses Apple's MLX for native GPU acceleration.\n\n**What it does:**\n\n\\- OpenAI-compatible API (drop-in replacement for your existing code)\n\n\\- Multimodal support: Text, Images, Video, Audio - all in one server\n\n\\- Continuous batching for concurrent users (3.4x speedup)\n\n\\- TTS in 10+ languages (Kokoro, Chatterbox models)\n\n\\- MCP tool calling support\n\n**Performance on M4 Max:**\n\n\\- Llama-3.2-1B-4bit → 464 tok/s\n\n\\- Qwen3-0.6B → 402 tok/s\n\n\\- Whisper STT → 197x real-time\n\nWorks with standard OpenAI Python SDK - just point it to localhost.\n\n**GitHub:** [https://github.com/waybarrios/vllm-mlx](https://github.com/waybarrios/vllm-mlx)"", ""author_fullname"": ""t2_57ierokx"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[P] vLLM-MLX: Native Apple Silicon LLM inference - 464 tok/s on M4 Max"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qelny9"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.78, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 21, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Project"", ""can_mod_post"": false, ""score"": 21, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""post_hint"": ""self"", ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768583110.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I built vLLM-MLX - a framework that uses Apple&amp;#39;s MLX for native GPU acceleration.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What it does:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- OpenAI-compatible API (drop-in replacement for your existing code)&lt;/p&gt;\n\n&lt;p&gt;- Multimodal support: Text, Images, Video, Audio - all in one server&lt;/p&gt;\n\n&lt;p&gt;- Continuous batching for concurrent users (3.4x speedup)&lt;/p&gt;\n\n&lt;p&gt;- TTS in 10+ languages (Kokoro, Chatterbox models)&lt;/p&gt;\n\n&lt;p&gt;- MCP tool calling support&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Performance on M4 Max:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Llama-3.2-1B-4bit → 464 tok/s&lt;/p&gt;\n\n&lt;p&gt;- Qwen3-0.6B → 402 tok/s&lt;/p&gt;\n\n&lt;p&gt;- Whisper STT → 197x real-time&lt;/p&gt;\n\n&lt;p&gt;Works with standard OpenAI Python SDK - just point it to localhost.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GitHub:&lt;/strong&gt; &lt;a href=\""https://github.com/waybarrios/vllm-mlx\""&gt;https://github.com/waybarrios/vllm-mlx&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""preview"": {""images"": [{""source"": {""url"": ""https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?auto=webp&amp;s=8a038454e6a2762a1a543f606fb53ae0422e549f"", ""width"": 1200, ""height"": 600}, ""resolutions"": [{""url"": ""https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=892966bdba333a956bfe2c383f77762610855143"", ""width"": 108, ""height"": 54}, {""url"": ""https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=46a40ad70ba8bde07abdce77f8bf351e7ecb20d6"", ""width"": 216, ""height"": 108}, {""url"": ""https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf1f1592fa93dbb1ad6e9f8cff0be4a5ced5d45c"", ""width"": 320, ""height"": 160}, {""url"": ""https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f8539fe5b27ab3b2c6f93564a02063fa844cda6"", ""width"": 640, ""height"": 320}, {""url"": ""https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4d4a56221df1f2350c53d2e8b1ac5848eb2a5e8b"", ""width"": 960, ""height"": 480}, {""url"": ""https://external-preview.redd.it/fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=836e2b9dd0d2699bec2d75e7abd0f288b9cea45b"", ""width"": 1080, ""height"": 540}], ""variants"": {}, ""id"": ""fBTqn5A_VMK5OvBsBnb5b0JpYvCkmnptt_UHJ212bNQ""}], ""enabled"": false}, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""c6dea51c-19d3-11f0-81a2-deb9d8e21ccb"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#7d659a"", ""id"": ""1qelny9"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""waybarrios"", ""discussion_type"": null, ""num_comments"": 4, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qelny9/p_vllmmlx_native_apple_silicon_llm_inference_464/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qelny9/p_vllmmlx_native_apple_silicon_llm_inference_464/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768583110.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qh1hyw,MachineLearning,Practical-Buddy6323,[R] Help with TMLR (Transactions in Machine Learning Research) Journal submission,"I recently submitted to TMLR (about 10 days ago now) and  I got the first review as well (almost 2 days ago) when should I submit the revised version of the paper ? Before the second review comes in or after all the reviews come in ? This is my first paper which I'm writing on my own which is why I'm asking these questions.

Appreciate you taking the time to answer, thanks!",21,12,0.96,1768821316.0,/r/MachineLearning/comments/1qh1hyw/r_help_with_tmlr_transactions_in_machine_learning/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""I recently submitted to TMLR (about 10 days ago now) and  I got the first review as well (almost 2 days ago) when should I submit the revised version of the paper ? Before the second review comes in or after all the reviews come in ? This is my first paper which I'm writing on my own which is why I'm asking these questions.\n\nAppreciate you taking the time to answer, thanks!"", ""author_fullname"": ""t2_1k5s41qgw8"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[R] Help with TMLR (Transactions in Machine Learning Research) Journal submission"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": ""three"", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qh1hyw"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.96, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 21, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Research"", ""can_mod_post"": false, ""score"": 21, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768821316.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;I recently submitted to TMLR (about 10 days ago now) and  I got the first review as well (almost 2 days ago) when should I submit the revised version of the paper ? Before the second review comes in or after all the reviews come in ? This is my first paper which I&amp;#39;m writing on my own which is why I&amp;#39;m asking these questions.&lt;/p&gt;\n\n&lt;p&gt;Appreciate you taking the time to answer, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""bb90e510-4e82-11e6-8635-0ee522e2349b"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#f1f10e"", ""id"": ""1qh1hyw"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""Practical-Buddy6323"", ""discussion_type"": null, ""num_comments"": 12, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qh1hyw/r_help_with_tmlr_transactions_in_machine_learning/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qh1hyw/r_help_with_tmlr_transactions_in_machine_learning/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768821316.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qg906l,MachineLearning,sulcantonin,[R] Event2Vec: Additive geometric embeddings for event sequences,"I’ve released the code for *Event2Vec*, a model for discrete event sequences that enforces a **linear additive** structure on the hidden state: the sequence representation is the sum of event embeddings.

The paper analyzes when the recurrent update converges to ideal additivity, and extends the model to a hyperbolic (Poincaré ball) variant using Möbius addition, which is better suited to hierarchical / tree‑like sequences.

Experiments include:

* A synthetic “life‑path” dataset showing interpretable trajectories and analogical reasoning via A − B + C over events.
* An unsupervised Brown Corpus POS experiment, where additive sequence embeddings cluster grammatical patterns and improve silhouette score vs a Word2Vec baseline.

Code (MIT, PyPI): short sklearn‑style estimator (`Event2Vec.fit / transform`) with CPU/GPU support and quickstart notebooks.

I’d be very interested in feedback on:

* How compelling you find additive sequence models vs RNNs / transformers / temporal point processes.
* Whether the hyperbolic variant / gyrovector‑space composition seems practically useful.

Happy to clarify details or discuss other experiment ideas.",17,8,0.95,1768744059.0,/r/MachineLearning/comments/1qg906l/r_event2vec_additive_geometric_embeddings_for/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""I’ve released the code for *Event2Vec*, a model for discrete event sequences that enforces a **linear additive** structure on the hidden state: the sequence representation is the sum of event embeddings.\n\nThe paper analyzes when the recurrent update converges to ideal additivity, and extends the model to a hyperbolic (Poincaré ball) variant using Möbius addition, which is better suited to hierarchical / tree‑like sequences.\n\nExperiments include:\n\n* A synthetic “life‑path” dataset showing interpretable trajectories and analogical reasoning via A − B + C over events.\n* An unsupervised Brown Corpus POS experiment, where additive sequence embeddings cluster grammatical patterns and improve silhouette score vs a Word2Vec baseline.\n\nCode (MIT, PyPI): short sklearn‑style estimator (`Event2Vec.fit / transform`) with CPU/GPU support and quickstart notebooks.\n\nI’d be very interested in feedback on:\n\n* How compelling you find additive sequence models vs RNNs / transformers / temporal point processes.\n* Whether the hyperbolic variant / gyrovector‑space composition seems practically useful.\n\nHappy to clarify details or discuss other experiment ideas."", ""author_fullname"": ""t2_77e3jpuf"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[R] Event2Vec: Additive geometric embeddings for event sequences"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": 70, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qg906l"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.95, ""author_flair_background_color"": null, ""ups"": 17, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": 140, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Project"", ""can_mod_post"": false, ""score"": 17, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""https://external-preview.redd.it/6_ohBgql2eGhSwKyc2oTj9BOYfHdM0FzAj6OJB6Vpso.png?width=140&amp;height=70&amp;auto=webp&amp;s=f3ad7cfe07f88e2a8d0d77864100b92e5d6c2290"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""post_hint"": ""link"", ""content_categories"": null, ""is_self"": false, ""subreddit_type"": ""public"", ""created"": 1768744059.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""github.com"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;I’ve released the code for &lt;em&gt;Event2Vec&lt;/em&gt;, a model for discrete event sequences that enforces a &lt;strong&gt;linear additive&lt;/strong&gt; structure on the hidden state: the sequence representation is the sum of event embeddings.&lt;/p&gt;\n\n&lt;p&gt;The paper analyzes when the recurrent update converges to ideal additivity, and extends the model to a hyperbolic (Poincaré ball) variant using Möbius addition, which is better suited to hierarchical / tree‑like sequences.&lt;/p&gt;\n\n&lt;p&gt;Experiments include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;A synthetic “life‑path” dataset showing interpretable trajectories and analogical reasoning via A − B + C over events.&lt;/li&gt;\n&lt;li&gt;An unsupervised Brown Corpus POS experiment, where additive sequence embeddings cluster grammatical patterns and improve silhouette score vs a Word2Vec baseline.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Code (MIT, PyPI): short sklearn‑style estimator (&lt;code&gt;Event2Vec.fit / transform&lt;/code&gt;) with CPU/GPU support and quickstart notebooks.&lt;/p&gt;\n\n&lt;p&gt;I’d be very interested in feedback on:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How compelling you find additive sequence models vs RNNs / transformers / temporal point processes.&lt;/li&gt;\n&lt;li&gt;Whether the hyperbolic variant / gyrovector‑space composition seems practically useful.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Happy to clarify details or discuss other experiment ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""url_overridden_by_dest"": ""https://github.com/sulcantonin/event2vec_public"", ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""preview"": {""images"": [{""source"": {""url"": ""https://external-preview.redd.it/6_ohBgql2eGhSwKyc2oTj9BOYfHdM0FzAj6OJB6Vpso.png?auto=webp&amp;s=266d9b9261084e1d1dac65483a047a7bed88a78c"", ""width"": 1200, ""height"": 600}, ""resolutions"": [{""url"": ""https://external-preview.redd.it/6_ohBgql2eGhSwKyc2oTj9BOYfHdM0FzAj6OJB6Vpso.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eb674497345af0fa03ca9e7a615bee72e9e5b284"", ""width"": 108, ""height"": 54}, {""url"": ""https://external-preview.redd.it/6_ohBgql2eGhSwKyc2oTj9BOYfHdM0FzAj6OJB6Vpso.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1564842eb316ad0c7125e59fc730ceba3612308f"", ""width"": 216, ""height"": 108}, {""url"": ""https://external-preview.redd.it/6_ohBgql2eGhSwKyc2oTj9BOYfHdM0FzAj6OJB6Vpso.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bdd58b331c6f167361781e6c18c15ba8cf64f0a9"", ""width"": 320, ""height"": 160}, {""url"": ""https://external-preview.redd.it/6_ohBgql2eGhSwKyc2oTj9BOYfHdM0FzAj6OJB6Vpso.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=dda2377ba06e509b437ea436542775e4989b4c5c"", ""width"": 640, ""height"": 320}, {""url"": ""https://external-preview.redd.it/6_ohBgql2eGhSwKyc2oTj9BOYfHdM0FzAj6OJB6Vpso.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2c89482187549ec72e1c18ff8963babb107e87c8"", ""width"": 960, ""height"": 480}, {""url"": ""https://external-preview.redd.it/6_ohBgql2eGhSwKyc2oTj9BOYfHdM0FzAj6OJB6Vpso.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=381d3b3f3698b8c2051726a326faf3187f1ca3dc"", ""width"": 1080, ""height"": 540}], ""variants"": {}, ""id"": ""6_ohBgql2eGhSwKyc2oTj9BOYfHdM0FzAj6OJB6Vpso""}], ""enabled"": false}, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""c6dea51c-19d3-11f0-81a2-deb9d8e21ccb"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""mod_note"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""num_reports"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#7d659a"", ""id"": ""1qg906l"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""sulcantonin"", ""discussion_type"": null, ""num_comments"": 8, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qg906l/r_event2vec_additive_geometric_embeddings_for/"", ""stickied"": false, ""url"": ""https://github.com/sulcantonin/event2vec_public"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768744059.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qec1h6,MachineLearning,Screech-1,[D] Does weight decay in RealNVP (Normalizing flows) encourage identity transforms?,"I’m looking for some opinions on the use of weight decay in RealNVP-style normalizing flows.

My concern is that blindly applying standard weight decay (L2 on parameters) may be actively harmful in this setting. In RealNVP, each coupling layer is explicitly structured so that small weights push the transformation toward the identity map. With weight decay, we’re therefore not just regularizing capacity, we are actually biasing the model towards doing nothing.

In flows, the identity transform is a perfectly valid (and often high-likelihood early) solution (especially if you zero init your scale networks which seems to be standard practice), so weight decay feels like it’s reinforcing a bad inductive bias. Most implementations seem to include weight decay by default, but I haven’t seen much discussion about whether it actually makes sense for invertible models.

EDIT:

Following this post, I took the liberty of exploring this question through a toy problem. The setup is intentionally simple: I train a RealNVP-style flow to map between a standard Gaussian and a learned latent distribution coming from another model I’m working on. The target latent distribution has very small variance (overall std ≈ 0.067, with some dimensions down at 1e-4), which makes the identity-map bias especially relevant.

I ran a small ablation comparing no weight decay vs standard L2 *(*1e-4), keeping everything else fixed.

With weight decay 0:

    === ABLATION CONFIG ===
      weight_decay: 0.0
      tanh_scale: 3.0
      grad_clip: 1.0
      lr: 0.001
      epochs: 2000
      print_every: 200
    
    Latents: mean=0.0008, std=0.0667
      per-dim std: min=0.0002, max=0.1173
    
    === TRAINING ===
    Epoch   200 | NLL:  -801.28 | z_std: 0.900 | inv_std: 0.0646 | base1: [0.06573893129825592, 0.04342599958181381, 0.08187682926654816]
    Epoch   400 | NLL:  -865.13 | z_std: 0.848 | inv_std: 0.0611 | base1: [0.10183795541524887, 0.05562306195497513, 0.14103063941001892]
    Epoch   600 | NLL:  -892.77 | z_std: 0.956 | inv_std: 0.0618 | base1: [0.12410587072372437, 0.06660845875740051, 0.1999545693397522]
    Epoch   800 | NLL:  -925.00 | z_std: 1.055 | inv_std: 0.0650 | base1: [0.13949117064476013, 0.07608211040496826, 0.2613525688648224]
    Epoch  1000 | NLL:  -952.22 | z_std: 0.957 | inv_std: 0.0651 | base1: [0.1513708531856537, 0.08401045948266983, 0.3233321011066437]
    Epoch  1200 | NLL:  -962.60 | z_std: 0.930 | inv_std: 0.0630 | base1: [0.16100724041461945, 0.09044866263866425, 0.385517954826355]
    Epoch  1400 | NLL:  -972.35 | z_std: 1.120 | inv_std: 0.0644 | base1: [0.16973918676376343, 0.09588785469532013, 0.4429493546485901]
    Epoch  1600 | NLL: -1003.05 | z_std: 1.034 | inv_std: 0.0614 | base1: [0.17728091776371002, 0.10034342855215073, 0.4981722831726074]
    Epoch  1800 | NLL: -1005.57 | z_std: 0.949 | inv_std: 0.0645 | base1: [0.18365693092346191, 0.10299171507358551, 0.5445704460144043]
    Epoch  2000 | NLL: -1027.24 | z_std: 0.907 | inv_std: 0.0676 | base1: [0.19001561403274536, 0.10608844459056854, 0.5936127305030823]
    
    === FINAL EVALUATION ===
    Target:  mean=0.0008, std=0.0667
    Forward: mean=0.0239, std=0.9074 (should be ~0, ~1)
    Inverse: mean=0.0009, std=0.0644 (should match target)

With weight decay 1e-4:

    === ABLATION CONFIG ===
      weight_decay: 0.0001
      tanh_scale: 3.0
      grad_clip: 1.0
      lr: 0.001
      epochs: 2000
      print_every: 200
    
    Latents: mean=0.0008, std=0.0667
      per-dim std: min=0.0002, max=0.1173
    
    === TRAINING ===
    Epoch   200 | NLL:  -766.17 | z_std: 0.813 | inv_std: 0.1576 | base1: [0.06523454189300537, 0.04702048376202583, 0.07113225013017654]
    Epoch   400 | NLL:  -795.67 | z_std: 1.064 | inv_std: 0.7390 | base1: [0.08956282585859299, 0.0620030015707016, 0.10142181813716888]
    Epoch   600 | NLL:  -786.70 | z_std: 1.004 | inv_std: 0.1259 | base1: [0.09346793591976166, 0.06835056096315384, 0.11534363776445389]
    Epoch   800 | NLL:  -772.45 | z_std: 1.146 | inv_std: 0.1531 | base1: [0.09313802421092987, 0.06970944255590439, 0.12027867138385773]
    Epoch  1000 | NLL:  -825.67 | z_std: 0.747 | inv_std: 0.1728 | base1: [0.09319467097520828, 0.06899876147508621, 0.12167126685380936]
    Epoch  1200 | NLL:  -817.38 | z_std: 0.911 | inv_std: 0.1780 | base1: [0.09275200963020325, 0.06717729568481445, 0.12130238860845566]
    Epoch  1400 | NLL:  -831.18 | z_std: 0.722 | inv_std: 0.1677 | base1: [0.0924605205655098, 0.0654158964753151, 0.1201595664024353]
    Epoch  1600 | NLL:  -833.45 | z_std: 0.889 | inv_std: 0.1919 | base1: [0.09225902706384659, 0.06358200311660767, 0.11815735697746277]
    Epoch  1800 | NLL:  -838.98 | z_std: 0.893 | inv_std: 0.1714 | base1: [0.09210160374641418, 0.06210005283355713, 0.11663311719894409]
    Epoch  2000 | NLL:  -832.70 | z_std: 0.812 | inv_std: 0.1860 | base1: [0.0919715166091919, 0.060423776507377625, 0.11383745074272156]
    
    === FINAL EVALUATION ===
    Target:  mean=0.0008, std=0.0667
    Forward: mean=-0.0090, std=0.8116 (should be ~0, ~1)
    Inverse: mean=0.0023, std=0.2111 (should match target)

* **Without weight decay**, the model steadily moves away from the identity. The inverse pass closely matches the target latent statistics, and the forward pass converges to something very close to a standard normal (std ≈ 0.91 by the end, still improving). NLL improves monotonically, and the learned base transform parameters keep growing, indicating the model is actually using its capacity.
* **With weight decay**, training is noticeably different. NLL plateaus much earlier and fluctuates. More importantly, the inverse mapping never fully contracts to the target latent distribution (final inverse std ≈ 0.21 vs target 0.067). The forward mapping also under-disperses (std ≈ 0.81).

Qualitatively, this looks exactly like the concern I raised originally: weight decay doesn’t just regularize complexity here. Now, I’m not claiming this means “never use weight decay in flows,” but in appears that indeed in certain settings one should definitely think twice :D.",15,6,0.84,1768557619.0,/r/MachineLearning/comments/1qec1h6/d_does_weight_decay_in_realnvp_normalizing_flows/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""I’m looking for some opinions on the use of weight decay in RealNVP-style normalizing flows.\n\nMy concern is that blindly applying standard weight decay (L2 on parameters) may be actively harmful in this setting. In RealNVP, each coupling layer is explicitly structured so that small weights push the transformation toward the identity map. With weight decay, we’re therefore not just regularizing capacity, we are actually biasing the model towards doing nothing.\n\nIn flows, the identity transform is a perfectly valid (and often high-likelihood early) solution (especially if you zero init your scale networks which seems to be standard practice), so weight decay feels like it’s reinforcing a bad inductive bias. Most implementations seem to include weight decay by default, but I haven’t seen much discussion about whether it actually makes sense for invertible models.\n\nEDIT:\n\nFollowing this post, I took the liberty of exploring this question through a toy problem. The setup is intentionally simple: I train a RealNVP-style flow to map between a standard Gaussian and a learned latent distribution coming from another model I’m working on. The target latent distribution has very small variance (overall std ≈ 0.067, with some dimensions down at 1e-4), which makes the identity-map bias especially relevant.\n\nI ran a small ablation comparing no weight decay vs standard L2 *(*1e-4), keeping everything else fixed.\n\nWith weight decay 0:\n\n    === ABLATION CONFIG ===\n      weight_decay: 0.0\n      tanh_scale: 3.0\n      grad_clip: 1.0\n      lr: 0.001\n      epochs: 2000\n      print_every: 200\n    \n    Latents: mean=0.0008, std=0.0667\n      per-dim std: min=0.0002, max=0.1173\n    \n    === TRAINING ===\n    Epoch   200 | NLL:  -801.28 | z_std: 0.900 | inv_std: 0.0646 | base1: [0.06573893129825592, 0.04342599958181381, 0.08187682926654816]\n    Epoch   400 | NLL:  -865.13 | z_std: 0.848 | inv_std: 0.0611 | base1: [0.10183795541524887, 0.05562306195497513, 0.14103063941001892]\n    Epoch   600 | NLL:  -892.77 | z_std: 0.956 | inv_std: 0.0618 | base1: [0.12410587072372437, 0.06660845875740051, 0.1999545693397522]\n    Epoch   800 | NLL:  -925.00 | z_std: 1.055 | inv_std: 0.0650 | base1: [0.13949117064476013, 0.07608211040496826, 0.2613525688648224]\n    Epoch  1000 | NLL:  -952.22 | z_std: 0.957 | inv_std: 0.0651 | base1: [0.1513708531856537, 0.08401045948266983, 0.3233321011066437]\n    Epoch  1200 | NLL:  -962.60 | z_std: 0.930 | inv_std: 0.0630 | base1: [0.16100724041461945, 0.09044866263866425, 0.385517954826355]\n    Epoch  1400 | NLL:  -972.35 | z_std: 1.120 | inv_std: 0.0644 | base1: [0.16973918676376343, 0.09588785469532013, 0.4429493546485901]\n    Epoch  1600 | NLL: -1003.05 | z_std: 1.034 | inv_std: 0.0614 | base1: [0.17728091776371002, 0.10034342855215073, 0.4981722831726074]\n    Epoch  1800 | NLL: -1005.57 | z_std: 0.949 | inv_std: 0.0645 | base1: [0.18365693092346191, 0.10299171507358551, 0.5445704460144043]\n    Epoch  2000 | NLL: -1027.24 | z_std: 0.907 | inv_std: 0.0676 | base1: [0.19001561403274536, 0.10608844459056854, 0.5936127305030823]\n    \n    === FINAL EVALUATION ===\n    Target:  mean=0.0008, std=0.0667\n    Forward: mean=0.0239, std=0.9074 (should be ~0, ~1)\n    Inverse: mean=0.0009, std=0.0644 (should match target)\n\nWith weight decay 1e-4:\n\n    === ABLATION CONFIG ===\n      weight_decay: 0.0001\n      tanh_scale: 3.0\n      grad_clip: 1.0\n      lr: 0.001\n      epochs: 2000\n      print_every: 200\n    \n    Latents: mean=0.0008, std=0.0667\n      per-dim std: min=0.0002, max=0.1173\n    \n    === TRAINING ===\n    Epoch   200 | NLL:  -766.17 | z_std: 0.813 | inv_std: 0.1576 | base1: [0.06523454189300537, 0.04702048376202583, 0.07113225013017654]\n    Epoch   400 | NLL:  -795.67 | z_std: 1.064 | inv_std: 0.7390 | base1: [0.08956282585859299, 0.0620030015707016, 0.10142181813716888]\n    Epoch   600 | NLL:  -786.70 | z_std: 1.004 | inv_std: 0.1259 | base1: [0.09346793591976166, 0.06835056096315384, 0.11534363776445389]\n    Epoch   800 | NLL:  -772.45 | z_std: 1.146 | inv_std: 0.1531 | base1: [0.09313802421092987, 0.06970944255590439, 0.12027867138385773]\n    Epoch  1000 | NLL:  -825.67 | z_std: 0.747 | inv_std: 0.1728 | base1: [0.09319467097520828, 0.06899876147508621, 0.12167126685380936]\n    Epoch  1200 | NLL:  -817.38 | z_std: 0.911 | inv_std: 0.1780 | base1: [0.09275200963020325, 0.06717729568481445, 0.12130238860845566]\n    Epoch  1400 | NLL:  -831.18 | z_std: 0.722 | inv_std: 0.1677 | base1: [0.0924605205655098, 0.0654158964753151, 0.1201595664024353]\n    Epoch  1600 | NLL:  -833.45 | z_std: 0.889 | inv_std: 0.1919 | base1: [0.09225902706384659, 0.06358200311660767, 0.11815735697746277]\n    Epoch  1800 | NLL:  -838.98 | z_std: 0.893 | inv_std: 0.1714 | base1: [0.09210160374641418, 0.06210005283355713, 0.11663311719894409]\n    Epoch  2000 | NLL:  -832.70 | z_std: 0.812 | inv_std: 0.1860 | base1: [0.0919715166091919, 0.060423776507377625, 0.11383745074272156]\n    \n    === FINAL EVALUATION ===\n    Target:  mean=0.0008, std=0.0667\n    Forward: mean=-0.0090, std=0.8116 (should be ~0, ~1)\n    Inverse: mean=0.0023, std=0.2111 (should match target)\n\n* **Without weight decay**, the model steadily moves away from the identity. The inverse pass closely matches the target latent statistics, and the forward pass converges to something very close to a standard normal (std ≈ 0.91 by the end, still improving). NLL improves monotonically, and the learned base transform parameters keep growing, indicating the model is actually using its capacity.\n* **With weight decay**, training is noticeably different. NLL plateaus much earlier and fluctuates. More importantly, the inverse mapping never fully contracts to the target latent distribution (final inverse std ≈ 0.21 vs target 0.067). The forward mapping also under-disperses (std ≈ 0.81).\n\nQualitatively, this looks exactly like the concern I raised originally: weight decay doesn’t just regularize complexity here. Now, I’m not claiming this means “never use weight decay in flows,” but in appears that indeed in certain settings one should definitely think twice :D."", ""author_fullname"": ""t2_14oaof"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] Does weight decay in RealNVP (Normalizing flows) encourage identity transforms?"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qec1h6"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 0.84, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 15, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Discussion"", ""can_mod_post"": false, ""score"": 15, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": 1768569855.0, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768557619.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;I’m looking for some opinions on the use of weight decay in RealNVP-style normalizing flows.&lt;/p&gt;\n\n&lt;p&gt;My concern is that blindly applying standard weight decay (L2 on parameters) may be actively harmful in this setting. In RealNVP, each coupling layer is explicitly structured so that small weights push the transformation toward the identity map. With weight decay, we’re therefore not just regularizing capacity, we are actually biasing the model towards doing nothing.&lt;/p&gt;\n\n&lt;p&gt;In flows, the identity transform is a perfectly valid (and often high-likelihood early) solution (especially if you zero init your scale networks which seems to be standard practice), so weight decay feels like it’s reinforcing a bad inductive bias. Most implementations seem to include weight decay by default, but I haven’t seen much discussion about whether it actually makes sense for invertible models.&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;Following this post, I took the liberty of exploring this question through a toy problem. The setup is intentionally simple: I train a RealNVP-style flow to map between a standard Gaussian and a learned latent distribution coming from another model I’m working on. The target latent distribution has very small variance (overall std ≈ 0.067, with some dimensions down at 1e-4), which makes the identity-map bias especially relevant.&lt;/p&gt;\n\n&lt;p&gt;I ran a small ablation comparing no weight decay vs standard L2 &lt;em&gt;(&lt;/em&gt;1e-4), keeping everything else fixed.&lt;/p&gt;\n\n&lt;p&gt;With weight decay 0:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;=== ABLATION CONFIG ===\n  weight_decay: 0.0\n  tanh_scale: 3.0\n  grad_clip: 1.0\n  lr: 0.001\n  epochs: 2000\n  print_every: 200\n\nLatents: mean=0.0008, std=0.0667\n  per-dim std: min=0.0002, max=0.1173\n\n=== TRAINING ===\nEpoch   200 | NLL:  -801.28 | z_std: 0.900 | inv_std: 0.0646 | base1: [0.06573893129825592, 0.04342599958181381, 0.08187682926654816]\nEpoch   400 | NLL:  -865.13 | z_std: 0.848 | inv_std: 0.0611 | base1: [0.10183795541524887, 0.05562306195497513, 0.14103063941001892]\nEpoch   600 | NLL:  -892.77 | z_std: 0.956 | inv_std: 0.0618 | base1: [0.12410587072372437, 0.06660845875740051, 0.1999545693397522]\nEpoch   800 | NLL:  -925.00 | z_std: 1.055 | inv_std: 0.0650 | base1: [0.13949117064476013, 0.07608211040496826, 0.2613525688648224]\nEpoch  1000 | NLL:  -952.22 | z_std: 0.957 | inv_std: 0.0651 | base1: [0.1513708531856537, 0.08401045948266983, 0.3233321011066437]\nEpoch  1200 | NLL:  -962.60 | z_std: 0.930 | inv_std: 0.0630 | base1: [0.16100724041461945, 0.09044866263866425, 0.385517954826355]\nEpoch  1400 | NLL:  -972.35 | z_std: 1.120 | inv_std: 0.0644 | base1: [0.16973918676376343, 0.09588785469532013, 0.4429493546485901]\nEpoch  1600 | NLL: -1003.05 | z_std: 1.034 | inv_std: 0.0614 | base1: [0.17728091776371002, 0.10034342855215073, 0.4981722831726074]\nEpoch  1800 | NLL: -1005.57 | z_std: 0.949 | inv_std: 0.0645 | base1: [0.18365693092346191, 0.10299171507358551, 0.5445704460144043]\nEpoch  2000 | NLL: -1027.24 | z_std: 0.907 | inv_std: 0.0676 | base1: [0.19001561403274536, 0.10608844459056854, 0.5936127305030823]\n\n=== FINAL EVALUATION ===\nTarget:  mean=0.0008, std=0.0667\nForward: mean=0.0239, std=0.9074 (should be ~0, ~1)\nInverse: mean=0.0009, std=0.0644 (should match target)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;With weight decay 1e-4:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;=== ABLATION CONFIG ===\n  weight_decay: 0.0001\n  tanh_scale: 3.0\n  grad_clip: 1.0\n  lr: 0.001\n  epochs: 2000\n  print_every: 200\n\nLatents: mean=0.0008, std=0.0667\n  per-dim std: min=0.0002, max=0.1173\n\n=== TRAINING ===\nEpoch   200 | NLL:  -766.17 | z_std: 0.813 | inv_std: 0.1576 | base1: [0.06523454189300537, 0.04702048376202583, 0.07113225013017654]\nEpoch   400 | NLL:  -795.67 | z_std: 1.064 | inv_std: 0.7390 | base1: [0.08956282585859299, 0.0620030015707016, 0.10142181813716888]\nEpoch   600 | NLL:  -786.70 | z_std: 1.004 | inv_std: 0.1259 | base1: [0.09346793591976166, 0.06835056096315384, 0.11534363776445389]\nEpoch   800 | NLL:  -772.45 | z_std: 1.146 | inv_std: 0.1531 | base1: [0.09313802421092987, 0.06970944255590439, 0.12027867138385773]\nEpoch  1000 | NLL:  -825.67 | z_std: 0.747 | inv_std: 0.1728 | base1: [0.09319467097520828, 0.06899876147508621, 0.12167126685380936]\nEpoch  1200 | NLL:  -817.38 | z_std: 0.911 | inv_std: 0.1780 | base1: [0.09275200963020325, 0.06717729568481445, 0.12130238860845566]\nEpoch  1400 | NLL:  -831.18 | z_std: 0.722 | inv_std: 0.1677 | base1: [0.0924605205655098, 0.0654158964753151, 0.1201595664024353]\nEpoch  1600 | NLL:  -833.45 | z_std: 0.889 | inv_std: 0.1919 | base1: [0.09225902706384659, 0.06358200311660767, 0.11815735697746277]\nEpoch  1800 | NLL:  -838.98 | z_std: 0.893 | inv_std: 0.1714 | base1: [0.09210160374641418, 0.06210005283355713, 0.11663311719894409]\nEpoch  2000 | NLL:  -832.70 | z_std: 0.812 | inv_std: 0.1860 | base1: [0.0919715166091919, 0.060423776507377625, 0.11383745074272156]\n\n=== FINAL EVALUATION ===\nTarget:  mean=0.0008, std=0.0667\nForward: mean=-0.0090, std=0.8116 (should be ~0, ~1)\nInverse: mean=0.0023, std=0.2111 (should match target)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Without weight decay&lt;/strong&gt;, the model steadily moves away from the identity. The inverse pass closely matches the target latent statistics, and the forward pass converges to something very close to a standard normal (std ≈ 0.91 by the end, still improving). NLL improves monotonically, and the learned base transform parameters keep growing, indicating the model is actually using its capacity.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;With weight decay&lt;/strong&gt;, training is noticeably different. NLL plateaus much earlier and fluctuates. More importantly, the inverse mapping never fully contracts to the target latent distribution (final inverse std ≈ 0.21 vs target 0.067). The forward mapping also under-disperses (std ≈ 0.81).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Qualitatively, this looks exactly like the concern I raised originally: weight decay doesn’t just regularize complexity here. Now, I’m not claiming this means “never use weight decay in flows,” but in appears that indeed in certain settings one should definitely think twice :D.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""15995904-19d4-11f0-b8c9-0eed6ea89bc1"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#26c4d9"", ""id"": ""1qec1h6"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""Screech-1"", ""discussion_type"": null, ""num_comments"": 6, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qec1h6/d_does_weight_decay_in_realnvp_normalizing_flows/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qec1h6/d_does_weight_decay_in_realnvp_normalizing_flows/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768557619.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qcf8cd,MachineLearning,Striking-Warning9533,[D] Some of CVPR 2026 Workshops are released,[https://openreview.net/group?id=thecvf.com/CVPR/2026/Workshop](https://openreview.net/group?id=thecvf.com/CVPR/2026/Workshop),15,4,1.0,1768369487.0,/r/MachineLearning/comments/1qcf8cd/d_some_of_cvpr_2026_workshops_are_released/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""[https://openreview.net/group?id=thecvf.com/CVPR/2026/Workshop](https://openreview.net/group?id=thecvf.com/CVPR/2026/Workshop)"", ""author_fullname"": ""t2_70mnmect"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] Some of CVPR 2026 Workshops are released"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": """", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qcf8cd"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 1.0, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 15, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""News"", ""can_mod_post"": false, ""score"": 15, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768369487.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;&lt;a href=\""https://openreview.net/group?id=thecvf.com/CVPR/2026/Workshop\""&gt;https://openreview.net/group?id=thecvf.com/CVPR/2026/Workshop&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""99686488-19d3-11f0-af46-82f19314795a"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#2fd067"", ""id"": ""1qcf8cd"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""Striking-Warning9533"", ""discussion_type"": null, ""num_comments"": 4, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qcf8cd/d_some_of_cvpr_2026_workshops_are_released/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qcf8cd/d_some_of_cvpr_2026_workshops_are_released/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768369487.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
1qg5ncu,MachineLearning,reutococco,[D] ICML26 LLM Review Policy,"ICML26 introduced a review type selection, where the author can decide whether LLMs can be used during their paper review, according to these two policies:

* **Policy A (Conservative):** Use of LLMs for reviewing is strictly prohibited.  
* **Policy B (Permissive):** ***Allowed***: Use of LLMs to help understand the paper and related works, and polish reviews. Submissions can be fed to privacy-compliant\* LLMs. ***Not allowed***: Ask LLMs about strengths/weaknesses, ask to suggest key points for the review, suggest an outline for the review, or write the full review *\*By “privacy-compliant”, we refer to LLM tools that do not use logged data for training and that place limits on data retention. This includes enterprise/institutional subscriptions to LLM APIs, consumer subscriptions with an explicit opt-out from training, and self-hosted LLMs. (We understand that this is an oversimplification.)*

I'm struggling to decide which one to select, any tips?",11,4,1.0,1768733501.0,/r/MachineLearning/comments/1qg5ncu/d_icml26_llm_review_policy/,"{""approved_at_utc"": null, ""subreddit"": ""MachineLearning"", ""selftext"": ""ICML26 introduced a review type selection, where the author can decide whether LLMs can be used during their paper review, according to these two policies:\n\n* **Policy A (Conservative):** Use of LLMs for reviewing is strictly prohibited.  \n* **Policy B (Permissive):** ***Allowed***: Use of LLMs to help understand the paper and related works, and polish reviews. Submissions can be fed to privacy-compliant\\* LLMs. ***Not allowed***: Ask LLMs about strengths/weaknesses, ask to suggest key points for the review, suggest an outline for the review, or write the full review *\\*By “privacy-compliant”, we refer to LLM tools that do not use logged data for training and that place limits on data retention. This includes enterprise/institutional subscriptions to LLM APIs, consumer subscriptions with an explicit opt-out from training, and self-hosted LLMs. (We understand that this is an oversimplification.)*\n\nI'm struggling to decide which one to select, any tips?"", ""author_fullname"": ""t2_6b7we2ye"", ""saved"": false, ""mod_reason_title"": null, ""gilded"": 0, ""clicked"": false, ""title"": ""[D] ICML26 LLM Review Policy"", ""link_flair_richtext"": [], ""subreddit_name_prefixed"": ""r/MachineLearning"", ""hidden"": false, ""pwls"": 6, ""link_flair_css_class"": ""three"", ""downs"": 0, ""thumbnail_height"": null, ""top_awarded_type"": null, ""hide_score"": false, ""name"": ""t3_1qg5ncu"", ""quarantine"": false, ""link_flair_text_color"": ""dark"", ""upvote_ratio"": 1.0, ""author_flair_background_color"": null, ""subreddit_type"": ""public"", ""ups"": 11, ""total_awards_received"": 0, ""media_embed"": {}, ""thumbnail_width"": null, ""author_flair_template_id"": null, ""is_original_content"": false, ""user_reports"": [], ""secure_media"": null, ""is_reddit_media_domain"": false, ""is_meta"": false, ""category"": null, ""secure_media_embed"": {}, ""link_flair_text"": ""Research"", ""can_mod_post"": false, ""score"": 11, ""approved_by"": null, ""is_created_from_ads_ui"": false, ""author_premium"": false, ""thumbnail"": ""self"", ""edited"": false, ""author_flair_css_class"": null, ""author_flair_richtext"": [], ""gildings"": {}, ""content_categories"": null, ""is_self"": true, ""mod_note"": null, ""created"": 1768733501.0, ""link_flair_type"": ""text"", ""wls"": 6, ""removed_by_category"": null, ""banned_by"": null, ""author_flair_type"": ""text"", ""domain"": ""self.MachineLearning"", ""allow_live_comments"": false, ""selftext_html"": ""&lt;!-- SC_OFF --&gt;&lt;div class=\""md\""&gt;&lt;p&gt;ICML26 introduced a review type selection, where the author can decide whether LLMs can be used during their paper review, according to these two policies:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Policy A (Conservative):&lt;/strong&gt; Use of LLMs for reviewing is strictly prohibited.  &lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Policy B (Permissive):&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;Allowed&lt;/em&gt;&lt;/strong&gt;: Use of LLMs to help understand the paper and related works, and polish reviews. Submissions can be fed to privacy-compliant* LLMs. &lt;strong&gt;&lt;em&gt;Not allowed&lt;/em&gt;&lt;/strong&gt;: Ask LLMs about strengths/weaknesses, ask to suggest key points for the review, suggest an outline for the review, or write the full review &lt;em&gt;\\&lt;/em&gt;By “privacy-compliant”, we refer to LLM tools that do not use logged data for training and that place limits on data retention. This includes enterprise/institutional subscriptions to LLM APIs, consumer subscriptions with an explicit opt-out from training, and self-hosted LLMs. (We understand that this is an oversimplification.)*&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m struggling to decide which one to select, any tips?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;"", ""likes"": null, ""suggested_sort"": null, ""banned_at_utc"": null, ""view_count"": null, ""archived"": false, ""no_follow"": false, ""is_crosspostable"": false, ""pinned"": false, ""over_18"": false, ""all_awardings"": [], ""awarders"": [], ""media_only"": false, ""link_flair_template_id"": ""bb90e510-4e82-11e6-8635-0ee522e2349b"", ""can_gild"": false, ""spoiler"": false, ""locked"": false, ""author_flair_text"": null, ""treatment_tags"": [], ""visited"": false, ""removed_by"": null, ""num_reports"": null, ""distinguished"": null, ""subreddit_id"": ""t5_2r3gv"", ""author_is_blocked"": false, ""mod_reason_by"": null, ""removal_reason"": null, ""link_flair_background_color"": ""#f1f10e"", ""id"": ""1qg5ncu"", ""is_robot_indexable"": true, ""report_reasons"": null, ""author"": ""reutococco"", ""discussion_type"": null, ""num_comments"": 4, ""send_replies"": true, ""contest_mode"": false, ""mod_reports"": [], ""author_patreon_flair"": false, ""author_flair_text_color"": null, ""permalink"": ""/r/MachineLearning/comments/1qg5ncu/d_icml26_llm_review_policy/"", ""stickied"": false, ""url"": ""https://www.reddit.com/r/MachineLearning/comments/1qg5ncu/d_icml26_llm_review_policy/"", ""subreddit_subscribers"": 3015954, ""created_utc"": 1768733501.0, ""num_crossposts"": 0, ""media"": null, ""is_video"": false}"
